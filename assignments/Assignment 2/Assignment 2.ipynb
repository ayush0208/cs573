{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "df = pd.read_csv('dating-full.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "type(df['race'][2])\r\n",
    "df.loc[0, 'race']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"'Asian/Pacific Islander/Asian-American'\""
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# df1 = df[['race','race_o','field']]\r\n",
    "# df1\r\n",
    "def contains_single_quote(s):\r\n",
    "    if s.startswith(\"'\") or s.endswith(\"'\"):\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        return False\r\n",
    "    \r\n",
    "strip_quotes_list = ['race','race_o','field']\r\n",
    "count = 0\r\n",
    "for index in df.index:\r\n",
    "    for col in strip_quotes_list:\r\n",
    "        if contains_single_quote(df.loc[index, col]):\r\n",
    "            count+=1\r\n",
    "            df.loc[index, col] = df.loc[index, col].replace('\\'','')\r\n",
    "print(\"Quotes removed from \" + str(count) + \" cells\")\r\n",
    "# df\r\n",
    "\r\n",
    "# for i, col in enumerate(df1.columns):\r\n",
    "#     df1.iloc[:, col] = df1.iloc[:, col].str.replace('\"','')\r\n",
    "# df1.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quotes removed from 8316 cells\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "def to_lower(df):\r\n",
    "    val = df['field'].values\r\n",
    "    count=0\r\n",
    "    for value in val:\r\n",
    "        if not(value.islower()):\r\n",
    "            count+=1 \r\n",
    "    df['field'] = df['field'].str.lower()\r\n",
    "    print(\"Standardized \" + str(count) + \" cells to lower case\")\r\n",
    "    return df\r\n",
    "df_lower = to_lower(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Standardized 5707 cells to lower case\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# arr = df['attractive_important'].values.tolist()\r\n",
    "# for val in arr:\r\n",
    "#     print(val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "label_encoding_list = ['gender','race','race_o','field']\r\n",
    "encoding_dict = {}\r\n",
    "for col in label_encoding_list:\r\n",
    "    unique_val = np.unique(df[col].values)\r\n",
    "    val_dict = {}\r\n",
    "    encoding_value = 0\r\n",
    "    for val in unique_val:\r\n",
    "        val_dict[val]=encoding_value\r\n",
    "        df[col].replace(val, encoding_value, inplace=True)\r\n",
    "        encoding_value+=1\r\n",
    "    encoding_dict[col] = val_dict\r\n",
    "print(\"Value assigned for male in column gender:\", encoding_dict['gender']['male'])\r\n",
    "print(\"Value assigned for European/Caucasian-American in column race:\", encoding_dict['race']['European/Caucasian-American'])\r\n",
    "print(\"Value assigned for Latino/Hispanic American in column race o:\", encoding_dict['race_o']['Latino/Hispanic American'])\r\n",
    "print(\"Value assigned for law in column field:\", encoding_dict['field']['law'])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value assigned for male in column gender: 1\n",
      "Value assigned for European/Caucasian-American in column race: 2\n",
      "Value assigned for Latino/Hispanic American in column race o: 3\n",
      "Value assigned for law in column field: 121\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 2, 3, 121)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "preference_scores_of_participant = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']\r\n",
    "preference_scores_of_partner = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\r\n",
    "rating_of_partner_from_participant = ['attractive_partner', 'sincere_partner', 'intelligence_parter','funny_partner', 'ambition_partner', 'shared_interests_partner']\r\n",
    "continuous_valued_columns = ['age', 'age_o', 'importance_same_race', 'importance_same_religion', \r\n",
    "        'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\r\n",
    "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\r\n",
    "       'attractive_important', 'sincere_important', 'intelligence_important',\r\n",
    "       'funny_important', 'ambition_important', 'shared_interests_important',\r\n",
    "       'attractive', 'sincere', 'intelligence', 'funny', 'ambition',\r\n",
    "       'attractive_partner', 'sincere_partner', 'intelligence_parter',\r\n",
    "       'funny_partner', 'ambition_partner', 'shared_interests_partner',\r\n",
    "       'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking',\r\n",
    "       'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\r\n",
    "       'music', 'shopping', 'yoga', 'interests_correlate',\r\n",
    "       'expected_happy_with_sd_people', 'like'\r\n",
    "    ]\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def normalize(df):\r\n",
    "    for ind in df.index:\r\n",
    "        total=0\r\n",
    "        for col in preference_scores_of_participant:\r\n",
    "            total+= df[col][ind]\r\n",
    "        for col in preference_scores_of_participant:\r\n",
    "            df.loc[ind, col] = df[col][ind]/total\r\n",
    "        total=0\r\n",
    "        for col in preference_scores_of_partner:\r\n",
    "            total+= df[col][ind]\r\n",
    "        for col in preference_scores_of_partner:\r\n",
    "            df.loc[ind, col] = df[col][ind]/total\r\n",
    "    for col in preference_scores_of_participant:\r\n",
    "        print(\"Mean of \"+ col + \": \" ,round(df[[col]].mean()[0], 2) )\r\n",
    "    for col in preference_scores_of_partner:\r\n",
    "        print(\"Mean of \"+ col + \": \" , round(df[[col]].mean()[0], 2) )\r\n",
    "            # df[col][ind] = df[col][ind]/total    \r\n",
    "normalize(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean of attractive_important:  0.22\n",
      "Mean of sincere_important:  0.17\n",
      "Mean of intelligence_important:  0.2\n",
      "Mean of funny_important:  0.17\n",
      "Mean of ambition_important:  0.11\n",
      "Mean of shared_interests_important:  0.12\n",
      "Mean of pref_o_attractive:  0.22\n",
      "Mean of pref_o_sincere:  0.17\n",
      "Mean of pref_o_intelligence:  0.2\n",
      "Mean of pref_o_funny:  0.17\n",
      "Mean of pref_o_ambitious:  0.11\n",
      "Mean of pref_o_shared_interests:  0.12\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>field</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6744 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  age_o  race  race_o  samerace  importance_same_race  \\\n",
       "0          0   21     27     0       2         0                     2   \n",
       "1          0   21     22     0       2         0                     2   \n",
       "2          0   21     23     0       2         0                     2   \n",
       "3          0   21     24     0       3         0                     2   \n",
       "4          0   21     25     0       2         0                     2   \n",
       "...      ...  ...    ...   ...     ...       ...                   ...   \n",
       "6739       1   25     28     2       4         0                     1   \n",
       "6740       1   25     26     2       2         1                     1   \n",
       "6741       1   25     22     2       2         1                     1   \n",
       "6742       1   25     27     2       0         0                     1   \n",
       "6743       1   25     22     2       0         0                     1   \n",
       "\n",
       "      importance_same_religion  field  pref_o_attractive  ...  theater  \\\n",
       "0                            4    121               0.35  ...        1   \n",
       "1                            4    121               0.60  ...        1   \n",
       "2                            4    121               0.30  ...        1   \n",
       "3                            4    121               0.30  ...        1   \n",
       "4                            4    121               0.50  ...        1   \n",
       "...                        ...    ...                ...  ...      ...   \n",
       "6739                         1     39               0.25  ...        7   \n",
       "6740                         1     39               0.10  ...        7   \n",
       "6741                         1     39               0.10  ...        7   \n",
       "6742                         1     39               0.10  ...        7   \n",
       "6743                         1     39               0.20  ...        7   \n",
       "\n",
       "      movies  concerts  music  shopping  yoga  interests_correlate  \\\n",
       "0         10        10      9         8     1                 0.14   \n",
       "1         10        10      9         8     1                 0.54   \n",
       "2         10        10      9         8     1                 0.61   \n",
       "3         10        10      9         8     1                 0.21   \n",
       "4         10        10      9         8     1                 0.25   \n",
       "...      ...       ...    ...       ...   ...                  ...   \n",
       "6739       9        10     10         7     3                 0.37   \n",
       "6740       9        10     10         7     3                 0.27   \n",
       "6741       9        10     10         7     3                 0.45   \n",
       "6742       9        10     10         7     3                 0.35   \n",
       "6743       9        10     10         7     3                 0.01   \n",
       "\n",
       "      expected_happy_with_sd_people  like  decision  \n",
       "0                                 3   7.0         1  \n",
       "1                                 3   7.0         1  \n",
       "2                                 3   7.0         1  \n",
       "3                                 3   6.0         1  \n",
       "4                                 3   6.0         0  \n",
       "...                             ...   ...       ...  \n",
       "6739                             10   5.0         0  \n",
       "6740                             10   4.0         0  \n",
       "6741                             10   6.0         0  \n",
       "6742                             10   6.0         0  \n",
       "6743                             10   4.0         0  \n",
       "\n",
       "[6744 rows x 53 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def data_trend_by_gender(df):\r\n",
    "    df_male = df[df['gender']==1]\r\n",
    "    df_female = df[df['gender']==0]\r\n",
    "\r\n",
    "    male = []\r\n",
    "    for col in preference_scores_of_participant:\r\n",
    "        mean = df_male[[col]].mean()[0]\r\n",
    "        # print(\"Mean of \"+ col + \": \" , mean)\r\n",
    "        male.append(mean)\r\n",
    "\r\n",
    "    female = []\r\n",
    "    for col in preference_scores_of_participant:\r\n",
    "        mean = df_female[[col]].mean()[0]\r\n",
    "        # print(\"Mean of \"+ col + \": \" , mean)\r\n",
    "        female.append(mean)\r\n",
    "        \r\n",
    "    barWidth = 0.25\r\n",
    "    plt.subplots(figsize =(15, 8))\r\n",
    "    \r\n",
    "    br1 = np.arange(len(male))\r\n",
    "    br2 = [x + barWidth for x in br1]\r\n",
    "    \r\n",
    "    # Make the plot\r\n",
    "    plt.bar(br1, male, color ='r', width = barWidth,\r\n",
    "            edgecolor ='grey', label ='Male')\r\n",
    "    plt.bar(br2, female, color ='b', width = barWidth,\r\n",
    "            edgecolor ='grey', label ='female')\r\n",
    "    \r\n",
    "    # Adding Xticks\r\n",
    "    plt.xlabel('Attributes', fontweight ='bold', fontsize = 15)\r\n",
    "    plt.ylabel('Mean', fontweight ='bold', fontsize = 15)\r\n",
    "    plt.xticks([r + barWidth for r in range(len(male))],\r\n",
    "            preference_scores_of_participant)\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "data_trend_by_gender(df)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "df_male = df[df['gender']==1]\r\n",
    "df\r\n",
    "# df_male['attractive_important'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>field</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Law</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Law</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Law</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>'Latino/Hispanic American'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Law</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Law</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Climate Dynamics'</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Climate Dynamics'</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Climate Dynamics'</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Climate Dynamics'</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Climate Dynamics'</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6744 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  age_o                                     race  \\\n",
       "0     female   21     27  'Asian/Pacific Islander/Asian-American'   \n",
       "1     female   21     22  'Asian/Pacific Islander/Asian-American'   \n",
       "2     female   21     23  'Asian/Pacific Islander/Asian-American'   \n",
       "3     female   21     24  'Asian/Pacific Islander/Asian-American'   \n",
       "4     female   21     25  'Asian/Pacific Islander/Asian-American'   \n",
       "...      ...  ...    ...                                      ...   \n",
       "6739    male   25     28              European/Caucasian-American   \n",
       "6740    male   25     26              European/Caucasian-American   \n",
       "6741    male   25     22              European/Caucasian-American   \n",
       "6742    male   25     27              European/Caucasian-American   \n",
       "6743    male   25     22              European/Caucasian-American   \n",
       "\n",
       "                                       race_o  samerace  importance_same_race  \\\n",
       "0                 European/Caucasian-American         0                     2   \n",
       "1                 European/Caucasian-American         0                     2   \n",
       "2                 European/Caucasian-American         0                     2   \n",
       "3                  'Latino/Hispanic American'         0                     2   \n",
       "4                 European/Caucasian-American         0                     2   \n",
       "...                                       ...       ...                   ...   \n",
       "6739                                    Other         0                     1   \n",
       "6740              European/Caucasian-American         1                     1   \n",
       "6741              European/Caucasian-American         1                     1   \n",
       "6742  'Asian/Pacific Islander/Asian-American'         0                     1   \n",
       "6743  'Asian/Pacific Islander/Asian-American'         0                     1   \n",
       "\n",
       "      importance_same_religion               field  pref_o_attractive  ...  \\\n",
       "0                            4                 Law               0.35  ...   \n",
       "1                            4                 Law               0.60  ...   \n",
       "2                            4                 Law               0.30  ...   \n",
       "3                            4                 Law               0.30  ...   \n",
       "4                            4                 Law               0.50  ...   \n",
       "...                        ...                 ...                ...  ...   \n",
       "6739                         1  'Climate Dynamics'               0.25  ...   \n",
       "6740                         1  'Climate Dynamics'               0.10  ...   \n",
       "6741                         1  'Climate Dynamics'               0.10  ...   \n",
       "6742                         1  'Climate Dynamics'               0.10  ...   \n",
       "6743                         1  'Climate Dynamics'               0.20  ...   \n",
       "\n",
       "      theater  movies  concerts  music  shopping  yoga  interests_correlate  \\\n",
       "0           1      10        10      9         8     1                 0.14   \n",
       "1           1      10        10      9         8     1                 0.54   \n",
       "2           1      10        10      9         8     1                 0.61   \n",
       "3           1      10        10      9         8     1                 0.21   \n",
       "4           1      10        10      9         8     1                 0.25   \n",
       "...       ...     ...       ...    ...       ...   ...                  ...   \n",
       "6739        7       9        10     10         7     3                 0.37   \n",
       "6740        7       9        10     10         7     3                 0.27   \n",
       "6741        7       9        10     10         7     3                 0.45   \n",
       "6742        7       9        10     10         7     3                 0.35   \n",
       "6743        7       9        10     10         7     3                 0.01   \n",
       "\n",
       "      expected_happy_with_sd_people  like  decision  \n",
       "0                                 3   7.0         1  \n",
       "1                                 3   7.0         1  \n",
       "2                                 3   7.0         1  \n",
       "3                                 3   6.0         1  \n",
       "4                                 3   6.0         0  \n",
       "...                             ...   ...       ...  \n",
       "6739                             10   5.0         0  \n",
       "6740                             10   4.0         0  \n",
       "6741                             10   6.0         0  \n",
       "6742                             10   6.0         0  \n",
       "6743                             10   4.0         0  \n",
       "\n",
       "[6744 rows x 53 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# col_values = []\r\n",
    "for col in rating_of_partner_from_participant:\r\n",
    "    print(\"col\", col)\r\n",
    "    count = len(np.unique(df[[col]]))\r\n",
    "    print(count)\r\n",
    "    col_values = np.unique(df[[col]])\r\n",
    "    success = []\r\n",
    "    for val in col_values:\r\n",
    "        den = df[df[col]==val].count()[0]\r\n",
    "        num = df[df[col]==val]['decision'].sum()\r\n",
    "        success_rate = num/den\r\n",
    "        success.append(success_rate)\r\n",
    "    plt.scatter(col_values,success)\r\n",
    "    plt.title(col)\r\n",
    "    plt.xlabel(\"Values in \" + col)\r\n",
    "    plt.ylabel(\"Success Rate\")\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "# print(col_values)\r\n",
    "# df['attractive_partner'].value_counts()\r\n",
    "# df[df['attractive_partner']==1]['decision'].sum()\r\n",
    "# df[df['attractive_partner']==0]['decision'].sum()\r\n",
    "# df[df['attractive_partner']==0].count()[0]\r\n",
    "# col_values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "len(df.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "for col in continuous_valued_columns:\r\n",
    "    # print(col)\r\n",
    "    min_val = 0\r\n",
    "    max_val = 10\r\n",
    "    if col=='age' or col == 'age_o':\r\n",
    "        min_val = 18\r\n",
    "        max_val = 58\r\n",
    "    elif col in preference_scores_of_participant or col in preference_scores_of_partner:\r\n",
    "        min_val = 0\r\n",
    "        max_val = 1\r\n",
    "    elif col == 'interests_correlate':\r\n",
    "        min_val = -1\r\n",
    "        max_val = 1\r\n",
    "    # print(min_val)\r\n",
    "    # print(max_val)\r\n",
    "    bins = np.linspace(min_val,max_val,6)\r\n",
    "    df.loc[df[col] < min_val, col] = max_val\r\n",
    "    df.loc[df[col] > max_val, col] = max_val\r\n",
    "    df[col] = pd.cut(df[col],bins, include_lowest=True)\r\n",
    "    print(col, df[col].value_counts().sort_index().values)\r\n",
    "    # s = df[col].value_counts()\r\n",
    "    # print(s)\r\n",
    "    \r\n",
    "# (df['age'] > 25)\r\n",
    "# df[df['age'] < (40)]\r\n",
    "# print(10)\r\n",
    "    # print(bins)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=category and int",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24620/1611013662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# print(max_val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__lt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__lt__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__le__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5500\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5501\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5503\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    268\u001b[0m     ):\n\u001b[0;32m    269\u001b[0m         \u001b[1;31m# Call the method on lvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalid_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;31m# allow categorical vs object dtype array comparisons for equality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\ops\\invalid.py\u001b[0m in \u001b[0;36minvalid_comparison\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid comparison between dtype={left.dtype} and {typ}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid comparison between dtype=category and int"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "# range_age = (18,59)\r\n",
    "# df[df['age']<=26].count()\r\n",
    "# # df1= df[df['age'] not in range_age].count()\r\n",
    "# # df1\r\n",
    "# df['age'].value_counts().sort_index().values\r\n",
    "len(continuous_valued_columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "df['shopping'].value_counts().sort_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-0.001, 2.0]    1093\n",
       "(2.0, 4.0]       1098\n",
       "(4.0, 6.0]       1709\n",
       "(6.0, 8.0]       1643\n",
       "(8.0, 10.0]      1201\n",
       "Name: shopping, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "test_df = df.sample(random_state=47, frac=0.2)\r\n",
    "train_df = df.drop(test_df.index)\r\n",
    "print(len(test_df))\r\n",
    "print(len(train_df))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1349\n",
      "5395\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"dating.csv\")\r\n",
    "#look into this why a column is being added\r\n",
    "df = df.drop([df.columns[0]], axis=1)\r\n",
    "def binning_continuous_valued_columns(df):\r\n",
    "    for col in continuous_valued_columns:\r\n",
    "        # print(col)\r\n",
    "        min_val = 0\r\n",
    "        max_val = 10\r\n",
    "        if col=='age' or col == 'age_o':\r\n",
    "            min_val = 18\r\n",
    "            max_val = 58\r\n",
    "        elif col in preference_scores_of_participant or col in preference_scores_of_partner:\r\n",
    "            min_val = 0\r\n",
    "            max_val = 1\r\n",
    "        elif col == 'interests_correlate':\r\n",
    "            min_val = -1\r\n",
    "            max_val = 1\r\n",
    "        # print(min_val)\r\n",
    "        # print(max_val)\r\n",
    "        bins = np.linspace(min_val,max_val,6)\r\n",
    "        df.loc[df[col] < min_val, col] = max_val\r\n",
    "        df.loc[df[col] > max_val, col] = max_val\r\n",
    "        df[col] = pd.cut(df[col],bins, include_lowest=True)\r\n",
    "        print('{}: '.format(col), df[col].value_counts().sort_index().values)\r\n",
    "        # s = df[col].value_counts()\r\n",
    "        # print(s)\r\n",
    "binning_continuous_valued_columns(df)\r\n",
    "# df\r\n",
    "# def prior_class_probability(df):\r\n",
    "#     positive = len(df[df['decision']==1])\r\n",
    "#     # positive\r\n",
    "#     negative = len(df) - positive\r\n",
    "#     # negative\r\n",
    "#     prob_positive = positive/len(df)\r\n",
    "#     prob_negative = negative/len(df)\r\n",
    "#     return prob_positive, prob_negative\r\n",
    "# pos, neg = prior_class_probability(df)\r\n",
    "# print(pos, neg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "lookup_table = {}\r\n",
    "value_counts = df['decision'].value_counts().sort_index()\r\n",
    "lookup_table['class_name'] = value_counts.index.to_numpy()\r\n",
    "lookup_table['class_count'] = value_counts.values\r\n",
    "lookup_table"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'class_name': array([0, 1], dtype=int64),\n",
       " 'class_count': array([3835, 2909], dtype=int64)}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data_columns = df.drop('decision', axis=1).columns\r\n",
    "data_columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'age_o', 'race', 'race_o', 'samerace',\n",
       "       'importance_same_race', 'importance_same_religion', 'field',\n",
       "       'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
       "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\n",
       "       'attractive_important', 'sincere_important', 'intelligence_important',\n",
       "       'funny_important', 'ambition_important', 'shared_interests_important',\n",
       "       'attractive', 'sincere', 'intelligence', 'funny', 'ambition',\n",
       "       'attractive_partner', 'sincere_partner', 'intelligence_parter',\n",
       "       'funny_partner', 'ambition_partner', 'shared_interests_partner',\n",
       "       'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking',\n",
       "       'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
       "       'music', 'shopping', 'yoga', 'interests_correlate',\n",
       "       'expected_happy_with_sd_people', 'like'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for col in data_columns:\r\n",
    "    lookup_table[col] = {}\r\n",
    "\r\n",
    "    counts = df.groupby('decision')[col].value_counts()\r\n",
    "    df_counts = counts.unstack('decision')\r\n",
    "    if df_counts.isna().any(axis=None):\r\n",
    "        df_counts.fillna(value=0, inplace = True)\r\n",
    "        df_counts+=1  # laplace smoothing I guess\r\n",
    "    df_probabilities = df_counts/df_counts.sum()\r\n",
    "    for val in df_probabilities.index:\r\n",
    "        probability = df_probabilities.loc[val].to_numpy()\r\n",
    "        lookup_table[col][val] = probability\r\n",
    "import pprint\r\n",
    "pprint.pprint(lookup_table)\r\n",
    "\r\n",
    "\r\n",
    "# feature = 'gender'\r\n",
    "# lookup_table[feature] = {}\r\n",
    "# df.groupby('decision')[feature].value_counts(normalize=True) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# feature = 'gender'\r\n",
    "# lookup_table[feature] = {}\r\n",
    "# df.groupby('decision')[feature].value_counts(normalize=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "decision  gender\n",
       "0         0         0.540548\n",
       "          1         0.459452\n",
       "1         1         0.575112\n",
       "          0         0.424888\n",
       "Name: gender, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "df = pd.read_csv(\"dating-binned.csv\")\r\n",
    "def create_lookup_table(df, target_col):\r\n",
    "    lookup_table = {}\r\n",
    "    value_counts = df[target_col].value_counts().sort_index()\r\n",
    "    lookup_table['class_name'] = value_counts.index.to_numpy()\r\n",
    "    lookup_table['class_count'] = value_counts.values\r\n",
    "\r\n",
    "    data_columns = df.drop(target_col, axis=1).columns\r\n",
    "    for col in data_columns:\r\n",
    "        lookup_table[col] = {}\r\n",
    "\r\n",
    "        counts = df.groupby('decision')[col].value_counts()\r\n",
    "        df_counts = counts.unstack('decision')\r\n",
    "        if df_counts.isna().any(axis=None):\r\n",
    "            df_counts.fillna(value=0, inplace = True)\r\n",
    "            df_counts+=1  # laplace smoothing I guess\r\n",
    "        df_probabilities = df_counts/df_counts.sum()\r\n",
    "        for val in df_probabilities.index:\r\n",
    "            probability = df_probabilities.loc[val].to_numpy()\r\n",
    "            lookup_table[col][val] = probability\r\n",
    "    return lookup_table\r\n",
    "result = create_lookup_table(df, 'decision')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "row = df.iloc[40]\r\n",
    "row\r\n",
    "row = row[:-1]\r\n",
    "row.index"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'age_o', 'race', 'race_o', 'samerace',\n",
       "       'importance_same_race', 'importance_same_religion', 'field',\n",
       "       'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
       "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\n",
       "       'attractive_important', 'sincere_important', 'intelligence_important',\n",
       "       'funny_important', 'ambition_important', 'shared_interests_important',\n",
       "       'attractive', 'sincere', 'intelligence', 'funny', 'ambition',\n",
       "       'attractive_partner', 'sincere_partner', 'intelligence_parter',\n",
       "       'funny_partner', 'ambition_partner', 'shared_interests_partner',\n",
       "       'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking',\n",
       "       'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
       "       'music', 'shopping', 'yoga', 'interests_correlate',\n",
       "       'expected_happy_with_sd_people', 'like'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "class_estimates = result['class_count']\r\n",
    "for feature in row.index:\r\n",
    "    try:\r\n",
    "        value = row[feature]\r\n",
    "        prob = result[feature][value]\r\n",
    "        class_estimates = class_estimates * prob\r\n",
    "    except KeyError:\r\n",
    "        continue\r\n",
    "\r\n",
    "class_estimates\r\n",
    "max_class_index = class_estimates.argmax()\r\n",
    "prediction = result['class_name'][max_class_index]\r\n",
    "prediction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def predict(row, result):\r\n",
    "    class_estimates = result['class_count']\r\n",
    "    row = row[:-1] # can be removed after we pass the dataset without target label column\r\n",
    "    for feature in row.index:\r\n",
    "        try:\r\n",
    "            value = row[feature]\r\n",
    "            prob = result[feature][value]\r\n",
    "            class_estimates = class_estimates * prob\r\n",
    "        except KeyError:\r\n",
    "            continue\r\n",
    "\r\n",
    "    class_estimates\r\n",
    "    max_class_index = class_estimates.argmax()\r\n",
    "    prediction = result['class_name'][max_class_index]\r\n",
    "    return prediction\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "predictions = df.apply(predict, axis=1, args=(result,))\r\n",
    "predictions.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "type(predictions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "type(df['decision'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "correct_predictions = predictions == df['decision']\r\n",
    "correct_predictions.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7685349940688019"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def accuracy(result, df, target_col):\r\n",
    "    predictions = df.apply(predict, axis=1, args=(result,))\r\n",
    "    correct_predictions = predictions == df[target_col]\r\n",
    "    return correct_predictions.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "train_df = pd.read_csv('./trainingSet.csv')\r\n",
    "test_df = pd.read_csv('./testSet.csv')\r\n",
    "learning_table = create_lookup_table(train_df, 'decision')\r\n",
    "print(\"Train:\",accuracy(learning_table, train_df))\r\n",
    "print(\"Test\", accuracy(learning_table, test_df))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 0.7749768303985172\n",
      "Test 0.7501853224610823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "def nbc(t_frac):\r\n",
    "    df = pd.read_csv('./trainingSet.csv')\r\n",
    "    train_df = df.sample(random_state=47, frac=t_frac)\r\n",
    "    target_col = 'decision'\r\n",
    "    test_df = pd.read_csv('./testSet.csv')\r\n",
    "    prob_table = create_lookup_table(train_df, target_col)\r\n",
    "    return prob_table, train_df, test_df\r\n",
    "# print(\"Training Accuracy: \",round(accuracy(prob_table, train_df), 2) )\r\n",
    "# print(\"Testing Accuracy: \", round(accuracy(prob_table, test_df), 2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "nbc(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'class_name': array([0, 1], dtype=int64),\n",
       "  'class_count': array([3060, 2335], dtype=int64),\n",
       "  'gender': {0: array([0.54771242, 0.41498929]),\n",
       "   1: array([0.45228758, 0.58501071])},\n",
       "  'age': {'(17.999, 18.2]': array([0.00227125, 0.00084854]),\n",
       "   '(18.8, 19.0]': array([0.00227125, 0.0012728 ]),\n",
       "   '(19.8, 20.0]': array([0.00616483, 0.00466695]),\n",
       "   '(20.8, 21.0]': array([0.02920182, 0.0492151 ]),\n",
       "   '(21.8, 22.0]': array([0.07365347, 0.07976241]),\n",
       "   '(22.8, 23.0]': array([0.1229721 , 0.11327959]),\n",
       "   '(23.8, 24.0]': array([0.11972745, 0.10988545]),\n",
       "   '(24.8, 25.0]': array([0.0908501 , 0.10182435]),\n",
       "   '(25.8, 26.0]': array([0.10772226, 0.08952058]),\n",
       "   '(26.8, 27.0]': array([0.12491888, 0.12940178]),\n",
       "   '(27.8, 28.0]': array([0.09669046, 0.09546033]),\n",
       "   '(28.8, 29.0]': array([0.06099935, 0.06618583]),\n",
       "   '(29.8, 30.0]': array([0.07916937, 0.05982181]),\n",
       "   '(30.8, 31.0]': array([0.00713822, 0.02163768]),\n",
       "   '(31.8, 32.0]': array([0.02920182, 0.02248621]),\n",
       "   '(32.8, 33.0]': array([0.01297859, 0.01824353]),\n",
       "   '(33.8, 34.0]': array([0.02011681, 0.01654646]),\n",
       "   '(34.8, 35.0]': array([0.00713822, 0.00721256]),\n",
       "   '(35.8, 36.0]': array([0.00032446, 0.00339415]),\n",
       "   '(37.8, 38.0]': array([0.00389358, 0.00169707]),\n",
       "   '(41.8, 42.0]': array([0.00194679, 0.00636402]),\n",
       "   '(54.8, 55.0]': array([0.00064893, 0.0012728 ])},\n",
       "  'age_o': {'(17.999, 18.2]': array([0.00162127, 0.00169563]),\n",
       "   '(18.8, 19.0]': array([0.00226978, 0.00254345]),\n",
       "   '(19.8, 20.0]': array([0.0035668 , 0.00678253]),\n",
       "   '(20.8, 21.0]': array([0.03891051, 0.03772785]),\n",
       "   '(21.8, 22.0]': array([0.08657588, 0.07460788]),\n",
       "   '(22.8, 23.0]': array([0.09857328, 0.11233574]),\n",
       "   '(23.8, 24.0]': array([0.10732815, 0.10258584]),\n",
       "   '(24.8, 25.0]': array([0.09338521, 0.12208563]),\n",
       "   '(25.8, 26.0]': array([0.10570687, 0.11106401]),\n",
       "   '(26.8, 27.0]': array([0.13035019, 0.13225943]),\n",
       "   '(27.8, 28.0]': array([0.08592737, 0.09410767]),\n",
       "   '(28.8, 29.0]': array([0.06549935, 0.06485799]),\n",
       "   '(29.8, 30.0]': array([0.06614786, 0.05934718]),\n",
       "   '(30.8, 31.0]': array([0.01588846, 0.01398898]),\n",
       "   '(31.8, 32.0]': array([0.03015564, 0.01610852]),\n",
       "   '(32.8, 33.0]': array([0.0226978, 0.0152607]),\n",
       "   '(33.8, 34.0]': array([0.01750973, 0.01441289]),\n",
       "   '(34.8, 35.0]': array([0.00680934, 0.00805426]),\n",
       "   '(35.8, 36.0]': array([0.00843061, 0.00254345]),\n",
       "   '(36.8, 37.0]': array([0.00129702, 0.00042391]),\n",
       "   '(37.8, 38.0]': array([0.00226978, 0.00339127]),\n",
       "   '(38.8, 39.0]': array([0.0042153 , 0.00127173]),\n",
       "   '(41.8, 42.0]': array([0.00324254, 0.00169563]),\n",
       "   '(54.8, 55.0]': array([0.00162127, 0.00084782])},\n",
       "  'race': {0: array([0.22810458, 0.2633833 ]),\n",
       "   1: array([0.04117647, 0.06124197]),\n",
       "   2: array([0.59542484, 0.53190578]),\n",
       "   3: array([0.07777778, 0.06680942]),\n",
       "   4: array([0.05751634, 0.07665953])},\n",
       "  'race_o': {0: array([0.27647059, 0.1987152 ]),\n",
       "   1: array([0.05163399, 0.05139186]),\n",
       "   2: array([0.53104575, 0.6       ]),\n",
       "   3: array([0.07287582, 0.08650964]),\n",
       "   4: array([0.06797386, 0.0633833 ])},\n",
       "  'samerace': {0: array([0.60849673, 0.57944325]),\n",
       "   1: array([0.39150327, 0.42055675])},\n",
       "  'importance_same_race': {'(-0.001, 0.05]': array([0.00098039, 0.00042827]),\n",
       "   '(0.95, 1.0]': array([0.29281046, 0.37301927]),\n",
       "   '(1.95, 2.0]': array([0.11960784, 0.10749465]),\n",
       "   '(2.95, 3.0]': array([0.12254902, 0.13319058]),\n",
       "   '(3.95, 4.0]': array([0.04542484, 0.06167024]),\n",
       "   '(4.95, 5.0]': array([0.0872549 , 0.06895075]),\n",
       "   '(5.95, 6.0]': array([0.06013072, 0.0732334 ]),\n",
       "   '(6.95, 7.0]': array([0.0754902 , 0.05781585]),\n",
       "   '(7.95, 8.0]': array([0.1       , 0.05781585]),\n",
       "   '(8.95, 9.0]': array([0.05980392, 0.0496788 ]),\n",
       "   '(9.95, 10.0]': array([0.03594771, 0.01670236])},\n",
       "  'importance_same_religion': {'(0.95, 1.0]': array([0.33627451, 0.42526767]),\n",
       "   '(1.95, 2.0]': array([0.10228758, 0.09293362]),\n",
       "   '(2.95, 3.0]': array([0.11568627, 0.1130621 ]),\n",
       "   '(3.95, 4.0]': array([0.05947712, 0.05952891]),\n",
       "   '(4.95, 5.0]': array([0.09771242, 0.06809422]),\n",
       "   '(5.95, 6.0]': array([0.08333333, 0.07837259]),\n",
       "   '(6.95, 7.0]': array([0.04705882, 0.04453961]),\n",
       "   '(7.95, 8.0]': array([0.06339869, 0.06937901]),\n",
       "   '(8.95, 9.0]': array([0.04183007, 0.02912206]),\n",
       "   '(9.95, 10.0]': array([0.05294118, 0.01970021])},\n",
       "  'field': {0: array([0.00336494, 0.00078616]),\n",
       "   1: array([0.0003059 , 0.00471698]),\n",
       "   2: array([0.00152952, 0.00117925]),\n",
       "   3: array([0.00152952, 0.00196541]),\n",
       "   4: array([0.00183542, 0.00117925]),\n",
       "   5: array([0.00214133, 0.00275157]),\n",
       "   6: array([0.00367085, 0.00078616]),\n",
       "   7: array([0.00305904, 0.00196541]),\n",
       "   8: array([0.00244723, 0.00117925]),\n",
       "   9: array([0.00917712, 0.00353774]),\n",
       "   10: array([0.00397675, 0.00235849]),\n",
       "   11: array([0.00091771, 0.00314465]),\n",
       "   12: array([0.00122362, 0.00235849]),\n",
       "   13: array([0.00336494, 0.00314465]),\n",
       "   14: array([0.00642398, 0.01257862]),\n",
       "   15: array([0.00367085, 0.00235849]),\n",
       "   16: array([0.00244723, 0.00039308]),\n",
       "   17: array([0.01651881, 0.01690252]),\n",
       "   18: array([0.00214133, 0.00039308]),\n",
       "   19: array([0.01223616, 0.0086478 ]),\n",
       "   20: array([0.00305904, 0.00275157]),\n",
       "   21: array([0.00397675, 0.00235849]),\n",
       "   22: array([0.00305904, 0.00393082]),\n",
       "   23: array([0.0776996 , 0.06171384]),\n",
       "   24: array([0.00122362, 0.00117925]),\n",
       "   25: array([0.00091771, 0.00196541]),\n",
       "   26: array([0.00856531, 0.01022013]),\n",
       "   27: array([0.00214133, 0.00314465]),\n",
       "   28: array([0.00367085, 0.00157233]),\n",
       "   29: array([0.00305904, 0.00157233]),\n",
       "   30: array([0.00305904, 0.00157233]),\n",
       "   31: array([0.00152952, 0.00157233]),\n",
       "   32: array([0.00244723, 0.00117925]),\n",
       "   33: array([0.00397675, 0.00117925]),\n",
       "   34: array([0.00367085, 0.00157233]),\n",
       "   35: array([0.00214133, 0.00353774]),\n",
       "   36: array([0.01193025, 0.01257862]),\n",
       "   37: array([0.00152952, 0.00511006]),\n",
       "   38: array([0.00367085, 0.00117925]),\n",
       "   39: array([0.00214133, 0.00157233]),\n",
       "   40: array([0.00244723, 0.00393082]),\n",
       "   41: array([0.00825941, 0.01336478]),\n",
       "   42: array([0.00183542, 0.00275157]),\n",
       "   43: array([0.00152952, 0.00275157]),\n",
       "   44: array([0.00091771, 0.00078616]),\n",
       "   45: array([0.0003059 , 0.00078616]),\n",
       "   46: array([0.00183542, 0.00589623]),\n",
       "   47: array([0.00428266, 0.00471698]),\n",
       "   48: array([0.00183542, 0.00196541]),\n",
       "   49: array([0.00152952, 0.00353774]),\n",
       "   50: array([0.00703579, 0.00078616]),\n",
       "   51: array([0.00458856, 0.00117925]),\n",
       "   52: array([0.00367085, 0.00235849]),\n",
       "   53: array([0.00336494, 0.00196541]),\n",
       "   54: array([0.00244723, 0.00314465]),\n",
       "   55: array([0.00152952, 0.00078616]),\n",
       "   56: array([0.00061181, 0.00275157]),\n",
       "   57: array([0.00091771, 0.00039308]),\n",
       "   58: array([0.00948302, 0.00393082]),\n",
       "   59: array([0.0003059 , 0.00314465]),\n",
       "   60: array([0.00122362, 0.00117925]),\n",
       "   61: array([0.00183542, 0.00078616]),\n",
       "   62: array([0.00061181, 0.00078616]),\n",
       "   63: array([0.00917712, 0.02044025]),\n",
       "   64: array([0.00305904, 0.00196541]),\n",
       "   65: array([0.00336494, 0.00157233]),\n",
       "   66: array([0.00611808, 0.00157233]),\n",
       "   67: array([0.00275314, 0.00196541]),\n",
       "   68: array([0.00305904, 0.00196541]),\n",
       "   69: array([0.00122362, 0.00589623]),\n",
       "   70: array([0.02263689, 0.02869497]),\n",
       "   71: array([0.00520037, 0.00393082]),\n",
       "   72: array([0.00367085, 0.00039308]),\n",
       "   73: array([0.00305904, 0.00275157]),\n",
       "   74: array([0.00611808, 0.01847484]),\n",
       "   75: array([0.00703579, 0.00668239]),\n",
       "   76: array([0.00244723, 0.00078616]),\n",
       "   77: array([0.00183542, 0.00078616]),\n",
       "   78: array([0.00183542, 0.00235849]),\n",
       "   79: array([0.00611808, 0.0043239 ]),\n",
       "   80: array([0.01254206, 0.01886792]),\n",
       "   81: array([0.00214133, 0.00353774]),\n",
       "   82: array([0.01682472, 0.01533019]),\n",
       "   83: array([0.00091771, 0.00471698]),\n",
       "   84: array([0.00244723, 0.00157233]),\n",
       "   85: array([0.00122362, 0.00235849]),\n",
       "   86: array([0.00061181, 0.00078616]),\n",
       "   87: array([0.00183542, 0.00157233]),\n",
       "   88: array([0.0003059 , 0.00235849]),\n",
       "   89: array([0.00244723, 0.00235849]),\n",
       "   90: array([0.00948302, 0.00628931]),\n",
       "   91: array([0.00061181, 0.00039308]),\n",
       "   92: array([0.00244723, 0.00157233]),\n",
       "   93: array([0.00214133, 0.00275157]),\n",
       "   94: array([0.0003059 , 0.00196541]),\n",
       "   95: array([0.00520037, 0.00353774]),\n",
       "   96: array([0.00152952, 0.0043239 ]),\n",
       "   97: array([0.00183542, 0.00117925]),\n",
       "   98: array([0.00122362, 0.00235849]),\n",
       "   99: array([0.00305904, 0.00196541]),\n",
       "   100: array([0.00428266, 0.00196541]),\n",
       "   101: array([0.00244723, 0.00275157]),\n",
       "   102: array([0.0003059 , 0.00117925]),\n",
       "   103: array([0.00122362, 0.00157233]),\n",
       "   104: array([0.00367085, 0.00117925]),\n",
       "   105: array([0.04374426, 0.03262579]),\n",
       "   106: array([0.00367085, 0.00117925]),\n",
       "   107: array([0.00183542, 0.00196541]),\n",
       "   108: array([0.00489446, 0.00157233]),\n",
       "   109: array([0.0003059 , 0.00314465]),\n",
       "   110: array([0.00122362, 0.00157233]),\n",
       "   111: array([0.00550627, 0.00393082]),\n",
       "   112: array([0.0003059 , 0.00157233]),\n",
       "   113: array([0.00275314, 0.00314465]),\n",
       "   114: array([0.00244723, 0.00078616]),\n",
       "   115: array([0.00091771, 0.00589623]),\n",
       "   116: array([0.00183542, 0.00196541]),\n",
       "   117: array([0.00152952, 0.00393082]),\n",
       "   118: array([0.00152952, 0.00353774]),\n",
       "   119: array([0.0003059 , 0.00078616]),\n",
       "   120: array([0.0079535 , 0.00628931]),\n",
       "   121: array([0.05598042, 0.07350629]),\n",
       "   122: array([0.00458856, 0.00157233]),\n",
       "   123: array([0.00275314, 0.00039308]),\n",
       "   124: array([0.00061181, 0.00314465]),\n",
       "   125: array([0.0079535 , 0.00393082]),\n",
       "   126: array([0.00183542, 0.00078616]),\n",
       "   127: array([0.00152952, 0.00275157]),\n",
       "   128: array([0.00091771, 0.00039308]),\n",
       "   129: array([0.00091771, 0.00117925]),\n",
       "   130: array([0.00336494, 0.00117925]),\n",
       "   131: array([0.00214133, 0.00393082]),\n",
       "   132: array([0.0003059 , 0.00707547]),\n",
       "   133: array([0.00305904, 0.00314465]),\n",
       "   134: array([0.00275314, 0.00196541]),\n",
       "   135: array([0.0003059 , 0.00117925]),\n",
       "   136: array([0.00550627, 0.00353774]),\n",
       "   137: array([0.00214133, 0.00275157]),\n",
       "   138: array([0.0003059 , 0.00196541]),\n",
       "   139: array([0.00152952, 0.00314465]),\n",
       "   140: array([0.01131845, 0.00943396]),\n",
       "   141: array([0.00152952, 0.0043239 ]),\n",
       "   142: array([0.05995717, 0.05935535]),\n",
       "   143: array([0.00397675, 0.00117925]),\n",
       "   144: array([0.00305904, 0.00314465]),\n",
       "   145: array([0.00214133, 0.00353774]),\n",
       "   146: array([0.00489446, 0.00628931]),\n",
       "   147: array([0.00367085, 0.00353774]),\n",
       "   148: array([0.01101254, 0.01257862]),\n",
       "   149: array([0.0003059 , 0.00786164]),\n",
       "   150: array([0.00122362, 0.00078616]),\n",
       "   151: array([0.00122362, 0.00471698]),\n",
       "   152: array([0.00397675, 0.00196541]),\n",
       "   153: array([0.00275314, 0.00117925]),\n",
       "   154: array([0.00336494, 0.00157233]),\n",
       "   155: array([0.00948302, 0.00393082]),\n",
       "   157: array([0.00214133, 0.0043239 ]),\n",
       "   158: array([0.0003059 , 0.00393082]),\n",
       "   159: array([0.00336494, 0.00117925]),\n",
       "   160: array([0.00275314, 0.00825472]),\n",
       "   161: array([0.00244723, 0.0043239 ]),\n",
       "   162: array([0.00275314, 0.00196541]),\n",
       "   163: array([0.00275314, 0.00117925]),\n",
       "   164: array([0.00367085, 0.00196541]),\n",
       "   165: array([0.00611808, 0.00314465]),\n",
       "   166: array([0.00214133, 0.00157233]),\n",
       "   167: array([0.00489446, 0.00039308]),\n",
       "   168: array([0.00672989, 0.00786164]),\n",
       "   169: array([0.00305904, 0.00117925]),\n",
       "   170: array([0.00214133, 0.00393082]),\n",
       "   171: array([0.00367085, 0.00196541]),\n",
       "   172: array([0.00061181, 0.00078616]),\n",
       "   173: array([0.00458856, 0.00117925]),\n",
       "   174: array([0.00703579, 0.01375786]),\n",
       "   175: array([0.0003059 , 0.00628931]),\n",
       "   176: array([0.0003059 , 0.00117925]),\n",
       "   177: array([0.01284797, 0.01139937]),\n",
       "   178: array([0.02018966, 0.02122642]),\n",
       "   179: array([0.00061181, 0.00235849]),\n",
       "   180: array([0.00428266, 0.00511006]),\n",
       "   181: array([0.00428266, 0.00314465]),\n",
       "   182: array([0.00183542, 0.00078616]),\n",
       "   183: array([0.00091771, 0.00039308]),\n",
       "   184: array([0.00122362, 0.00589623]),\n",
       "   185: array([0.00152952, 0.00196541]),\n",
       "   186: array([0.00336494, 0.00825472]),\n",
       "   187: array([0.00214133, 0.00117925]),\n",
       "   188: array([0.00183542, 0.00039308]),\n",
       "   189: array([0.00397675, 0.00275157]),\n",
       "   190: array([0.00061181, 0.00117925]),\n",
       "   191: array([0.00367085, 0.00078616]),\n",
       "   192: array([0.05353319, 0.03301887]),\n",
       "   193: array([0.00336494, 0.00275157]),\n",
       "   194: array([0.01713062, 0.01965409]),\n",
       "   195: array([0.00183542, 0.00117925]),\n",
       "   196: array([0.00122362, 0.00196541]),\n",
       "   197: array([0.00305904, 0.00117925]),\n",
       "   198: array([0.00336494, 0.00078616]),\n",
       "   199: array([0.00611808, 0.00314465]),\n",
       "   200: array([0.00122362, 0.00078616]),\n",
       "   201: array([0.00244723, 0.00314465]),\n",
       "   202: array([0.00214133, 0.00235849]),\n",
       "   203: array([0.00183542, 0.00235849]),\n",
       "   204: array([0.00244723, 0.00471698]),\n",
       "   205: array([0.00214133, 0.00471698]),\n",
       "   206: array([0.00275314, 0.00078616]),\n",
       "   207: array([0.00489446, 0.00786164]),\n",
       "   208: array([0.00275314, 0.00039308]),\n",
       "   209: array([0.00183542, 0.00471698])},\n",
       "  'pref_o_attractive': {'(-0.001, 0.005]': array([0.00224719, 0.00334728]),\n",
       "   '(0.015, 0.02]': array([0.00064205, 0.00083682]),\n",
       "   '(0.045, 0.05]': array([0.01091493, 0.00460251]),\n",
       "   '(0.065, 0.07]': array([0.00481541, 0.00627615]),\n",
       "   '(0.07, 0.075]': array([0.00513644, 0.00083682]),\n",
       "   '(0.075, 0.08]': array([0.00321027, 0.00125523]),\n",
       "   '(0.08, 0.085]': array([0.00321027, 0.00083682]),\n",
       "   '(0.085, 0.09]': array([0.00449438, 0.00627615]),\n",
       "   '(0.09, 0.095]': array([0.00064205, 0.00209205]),\n",
       "   '(0.095, 0.1]': array([0.10754414, 0.09372385]),\n",
       "   '(0.105, 0.11]': array([0.00449438, 0.00125523]),\n",
       "   '(0.11, 0.115]': array([0.00481541, 0.00209205]),\n",
       "   '(0.115, 0.12]': array([0.00674157, 0.01841004]),\n",
       "   '(0.12, 0.125]': array([0.00160514, 0.00209205]),\n",
       "   '(0.125, 0.13]': array([0.00128411, 0.00083682]),\n",
       "   '(0.13, 0.135]': array([0.00674157, 0.00753138]),\n",
       "   '(0.135, 0.14]': array([0.0141252 , 0.02803347]),\n",
       "   '(0.14, 0.145]': array([0.00385233, 0.01213389]),\n",
       "   '(0.145, 0.15]': array([0.10786517, 0.11966527]),\n",
       "   '(0.15, 0.155]': array([0.02022472, 0.03096234]),\n",
       "   '(0.155, 0.16]': array([0.03467095, 0.02677824]),\n",
       "   '(0.16, 0.165]': array([0.00995185, 0.00711297]),\n",
       "   '(0.165, 0.17]': array([0.02792937, 0.02468619]),\n",
       "   '(0.17, 0.175]': array([0.0105939 , 0.01297071]),\n",
       "   '(0.175, 0.18]': array([0.01990369, 0.01589958]),\n",
       "   '(0.18, 0.185]': array([0.00674157, 0.00711297]),\n",
       "   '(0.185, 0.19]': array([0.01444623, 0.01380753]),\n",
       "   '(0.19, 0.195]': array([0.00481541, 0.00251046]),\n",
       "   '(0.195, 0.2]': array([0.19325843, 0.19121339]),\n",
       "   '(0.2, 0.205]': array([0.00064205, 0.00292887]),\n",
       "   '(0.205, 0.21]': array([0.01861958, 0.00920502]),\n",
       "   '(0.21, 0.215]': array([0.00449438, 0.00669456]),\n",
       "   '(0.215, 0.22]': array([0.00674157, 0.00711297]),\n",
       "   '(0.22, 0.225]': array([0.00256822, 0.00292887]),\n",
       "   '(0.225, 0.23]': array([0.00449438, 0.00794979]),\n",
       "   '(0.235, 0.24]': array([0.00930979, 0.00502092]),\n",
       "   '(0.245, 0.25]': array([0.10369181, 0.08619247]),\n",
       "   '(0.255, 0.26]': array([0.00160514, 0.00292887]),\n",
       "   '(0.265, 0.27]': array([0.00256822, 0.00460251]),\n",
       "   '(0.275, 0.28]': array([0.00385233, 0.00376569]),\n",
       "   '(0.295, 0.3]': array([0.07223114, 0.07740586]),\n",
       "   '(0.315, 0.32]': array([0.00128411, 0.00292887]),\n",
       "   '(0.33, 0.335]': array([0.00417335, 0.00376569]),\n",
       "   '(0.345, 0.35]': array([0.02536116, 0.02761506]),\n",
       "   '(0.395, 0.4]': array([0.04751204, 0.02719665]),\n",
       "   '(0.445, 0.45]': array([0.00288925, 0.00502092]),\n",
       "   '(0.495, 0.5]': array([0.02985554, 0.0376569 ]),\n",
       "   '(0.545, 0.55]': array([0.00256822, 0.00167364]),\n",
       "   '(0.575, 0.58]': array([0.00256822, 0.00376569]),\n",
       "   '(0.595, 0.6]': array([0.00738363, 0.00920502]),\n",
       "   '(0.695, 0.7]': array([0.00256822, 0.00753138]),\n",
       "   '(0.745, 0.75]': array([0.00321027, 0.0041841 ]),\n",
       "   '(0.895, 0.9]': array([0.00032103, 0.00209205]),\n",
       "   '(0.945, 0.95]': array([0.00224719, 0.00251046]),\n",
       "   '(0.995, 1.0]': array([0.00032103, 0.00292887])},\n",
       "  'pref_o_sincere': {'(-0.001, 0.005]': array([0.01675258, 0.03026482]),\n",
       "   '(0.005, 0.01]': array([0.00225515, 0.00252207]),\n",
       "   '(0.015, 0.02]': array([0.00225515, 0.00336276]),\n",
       "   '(0.025, 0.03]': array([0.00451031, 0.00546448]),\n",
       "   '(0.045, 0.05]': array([0.03576031, 0.03783102]),\n",
       "   '(0.05, 0.055]': array([0.00386598, 0.00168138]),\n",
       "   '(0.065, 0.07]': array([0.0054768 , 0.00546448]),\n",
       "   '(0.075, 0.08]': array([0.00579897, 0.00294241]),\n",
       "   '(0.095, 0.1]': array([0.09890464, 0.1223203 ]),\n",
       "   '(0.105, 0.11]': array([0.00708763, 0.00504414]),\n",
       "   '(0.11, 0.115]': array([0.00483247, 0.00462379]),\n",
       "   '(0.115, 0.12]': array([0.00225515, 0.00252207]),\n",
       "   '(0.12, 0.125]': array([0.00612113, 0.00252207]),\n",
       "   '(0.125, 0.13]': array([0.00128866, 0.00294241]),\n",
       "   '(0.13, 0.135]': array([0.00032216, 0.01345103]),\n",
       "   '(0.135, 0.14]': array([0.00837629, 0.01261034]),\n",
       "   '(0.14, 0.145]': array([0.00128866, 0.00336276]),\n",
       "   '(0.145, 0.15]': array([0.11920103, 0.12105927]),\n",
       "   '(0.15, 0.155]': array([0.00418814, 0.00210172]),\n",
       "   '(0.155, 0.16]': array([0.02963918, 0.02269861]),\n",
       "   '(0.16, 0.165]': array([0.00676546, 0.01639344]),\n",
       "   '(0.165, 0.17]': array([0.03640464, 0.02690206]),\n",
       "   '(0.17, 0.175]': array([0.02061856, 0.02900378]),\n",
       "   '(0.175, 0.18]': array([0.04768041, 0.04749895]),\n",
       "   '(0.18, 0.185]': array([0.00869845, 0.01050862]),\n",
       "   '(0.185, 0.19]': array([0.01771907, 0.01513241]),\n",
       "   '(0.19, 0.195]': array([0.02545103, 0.02017654]),\n",
       "   '(0.195, 0.2]': array([0.27190722, 0.26313577]),\n",
       "   '(0.2, 0.205]': array([0.00451031, 0.00462379]),\n",
       "   '(0.205, 0.21]': array([0.01610825, 0.0037831 ]),\n",
       "   '(0.21, 0.215]': array([0.00418814, 0.00294241]),\n",
       "   '(0.215, 0.22]': array([0.01224227, 0.00420345]),\n",
       "   '(0.22, 0.225]': array([0.00418814, 0.00294241]),\n",
       "   '(0.225, 0.23]': array([0.00418814, 0.00798655]),\n",
       "   '(0.23, 0.235]': array([0.00289948, 0.00168138]),\n",
       "   '(0.235, 0.24]': array([0.00676546, 0.00546448]),\n",
       "   '(0.245, 0.25]': array([0.0744201 , 0.07398066]),\n",
       "   '(0.255, 0.26]': array([0.00354381, 0.00084069]),\n",
       "   '(0.295, 0.3]': array([0.04735825, 0.03783102]),\n",
       "   '(0.315, 0.32]': array([0.00096649, 0.00420345]),\n",
       "   '(0.345, 0.35]': array([0.00708763, 0.0075662 ]),\n",
       "   '(0.395, 0.4]': array([0.0128866 , 0.00630517]),\n",
       "   '(0.465, 0.47]': array([0.00257732, 0.00126103]),\n",
       "   '(0.595, 0.6]': array([0.00064433, 0.00084069])},\n",
       "  'pref_o_intelligence': {'(-0.001, 0.005]': array([0.01032924, 0.01390645]),\n",
       "   '(0.005, 0.01]': array([0.00419626, 0.00379267]),\n",
       "   '(0.015, 0.02]': array([0.00032279, 0.00210704]),\n",
       "   '(0.045, 0.05]': array([0.01484829, 0.00589971]),\n",
       "   '(0.075, 0.08]': array([0.00258231, 0.00379267]),\n",
       "   '(0.095, 0.1]': array([0.07617818, 0.05983987]),\n",
       "   '(0.1, 0.105]': array([0.00161394, 0.00126422]),\n",
       "   '(0.11, 0.115]': array([0.00161394, 0.00168563]),\n",
       "   '(0.145, 0.15]': array([0.07520981, 0.08006743]),\n",
       "   '(0.15, 0.155]': array([0.00322789, 0.0054783 ]),\n",
       "   '(0.155, 0.16]': array([0.01872176, 0.01769912]),\n",
       "   '(0.16, 0.165]': array([0.00258231, 0.00589971]),\n",
       "   '(0.165, 0.17]': array([0.0232408 , 0.02275601]),\n",
       "   '(0.17, 0.175]': array([0.02194964, 0.0278129 ]),\n",
       "   '(0.175, 0.18]': array([0.05422853, 0.0450906 ]),\n",
       "   '(0.18, 0.185]': array([0.00613299, 0.01432786]),\n",
       "   '(0.185, 0.19]': array([0.03163331, 0.03118416]),\n",
       "   '(0.19, 0.195]': array([0.0116204 , 0.02654867]),\n",
       "   '(0.195, 0.2]': array([0.30923176, 0.32448378]),\n",
       "   '(0.2, 0.205]': array([0.00516462, 0.00421408]),\n",
       "   '(0.205, 0.21]': array([0.02098128, 0.01432786]),\n",
       "   '(0.21, 0.215]': array([0.00839251, 0.01179941]),\n",
       "   '(0.215, 0.22]': array([0.00806972, 0.00294985]),\n",
       "   '(0.22, 0.225]': array([0.01226598, 0.01011378]),\n",
       "   '(0.225, 0.23]': array([0.01000646, 0.0109566 ]),\n",
       "   '(0.23, 0.235]': array([0.00806972, 0.00463548]),\n",
       "   '(0.235, 0.24]': array([0.00742414, 0.00210704]),\n",
       "   '(0.245, 0.25]': array([0.12298257, 0.12305099]),\n",
       "   '(0.265, 0.27]': array([0.00258231, 0.00252845]),\n",
       "   '(0.27, 0.275]': array([0.00064558, 0.00210704]),\n",
       "   '(0.275, 0.28]': array([0.00677857, 0.00927097]),\n",
       "   '(0.295, 0.3]': array([0.07650097, 0.06911083]),\n",
       "   '(0.315, 0.32]': array([0.00451904, 0.00126422]),\n",
       "   '(0.345, 0.35]': array([0.01581666, 0.01643489]),\n",
       "   '(0.395, 0.4]': array([0.00903809, 0.00758534]),\n",
       "   '(0.425, 0.43]': array([0.00258231, 0.00126422]),\n",
       "   '(0.445, 0.45]': array([0.00516462, 0.00252845]),\n",
       "   '(0.495, 0.5]': array([0.00355068, 0.01011378])},\n",
       "  'pref_o_funny': {'(-0.001, 0.005]': array([0.00354724, 0.00631313]),\n",
       "   '(0.005, 0.01]': array([0.00225734, 0.00252525]),\n",
       "   '(0.015, 0.02]': array([0.00032248, 0.00210438]),\n",
       "   '(0.025, 0.03]': array([0.00161238, 0.00378788]),\n",
       "   '(0.045, 0.05]': array([0.03740729, 0.0206229 ]),\n",
       "   '(0.075, 0.08]': array([0.00515963, 0.00505051]),\n",
       "   '(0.095, 0.1]': array([0.14092228, 0.13257576]),\n",
       "   '(0.1, 0.105]': array([0.00161238, 0.00126263]),\n",
       "   '(0.11, 0.115]': array([0.00161238, 0.0016835 ]),\n",
       "   '(0.115, 0.12]': array([0.01096421, 0.01094276]),\n",
       "   '(0.12, 0.125]': array([0.00096743, 0.00505051]),\n",
       "   '(0.125, 0.13]': array([0.00902935, 0.00799663]),\n",
       "   '(0.135, 0.14]': array([0.01257659, 0.00841751]),\n",
       "   '(0.14, 0.145]': array([0.00161238, 0.00210438]),\n",
       "   '(0.145, 0.15]': array([0.16091583, 0.13888889]),\n",
       "   '(0.155, 0.16]': array([0.03966462, 0.03324916]),\n",
       "   '(0.16, 0.165]': array([0.00773944, 0.01010101]),\n",
       "   '(0.165, 0.17]': array([0.04482425, 0.03619529]),\n",
       "   '(0.17, 0.175]': array([0.02225089, 0.0256734 ]),\n",
       "   '(0.175, 0.18]': array([0.03966462, 0.03198653]),\n",
       "   '(0.18, 0.185]': array([0.00838439, 0.01809764]),\n",
       "   '(0.185, 0.19]': array([0.01870364, 0.01430976]),\n",
       "   '(0.19, 0.195]': array([0.01967107, 0.03619529]),\n",
       "   '(0.195, 0.2]': array([0.23153821, 0.27483165]),\n",
       "   '(0.2, 0.205]': array([0.00483715, 0.0016835 ]),\n",
       "   '(0.205, 0.21]': array([0.00644953, 0.00462963]),\n",
       "   '(0.21, 0.215]': array([0.0096743 , 0.00757576]),\n",
       "   '(0.215, 0.22]': array([0.00999678, 0.00715488]),\n",
       "   '(0.22, 0.225]': array([0.01386649, 0.00799663]),\n",
       "   '(0.225, 0.23]': array([0.00612706, 0.00715488]),\n",
       "   '(0.23, 0.235]': array([0.00290229, 0.00210438]),\n",
       "   '(0.235, 0.24]': array([0.00451467, 0.00589226]),\n",
       "   '(0.245, 0.25]': array([0.06901   , 0.06944444]),\n",
       "   '(0.265, 0.27]': array([0.00096743, 0.00252525]),\n",
       "   '(0.27, 0.275]': array([0.00257981, 0.00462963]),\n",
       "   '(0.275, 0.28]': array([0.00225734, 0.00126263]),\n",
       "   '(0.295, 0.3]': array([0.03160271, 0.03282828]),\n",
       "   '(0.345, 0.35]': array([0.00257981, 0.003367  ]),\n",
       "   '(0.395, 0.4]': array([0.0054821 , 0.00757576]),\n",
       "   '(0.445, 0.45]': array([0.00225734, 0.00210438]),\n",
       "   '(0.495, 0.5]': array([0.00193486, 0.00210438])},\n",
       "  'pref_o_ambitious': {'(-0.001, 0.005]': array([0.09745079, 0.09898905]),\n",
       "   '(0.005, 0.01]': array([0.00548564, 0.00716091]),\n",
       "   '(0.015, 0.02]': array([0.00709906, 0.00758214]),\n",
       "   '(0.02, 0.025]': array([0.00580833, 0.00336984]),\n",
       "   '(0.025, 0.03]': array([0.01355276, 0.01221567]),\n",
       "   '(0.035, 0.04]': array([0.00354953, 0.00210615]),\n",
       "   '(0.045, 0.05]': array([0.14069055, 0.13016007]),\n",
       "   '(0.055, 0.06]': array([0.01419813, 0.00716091]),\n",
       "   '(0.06, 0.065]': array([0.00290416, 0.0042123 ]),\n",
       "   '(0.065, 0.07]': array([0.00935786, 0.00716091]),\n",
       "   '(0.075, 0.08]': array([0.01419813, 0.01347936]),\n",
       "   '(0.085, 0.09]': array([0.00354953, 0.00084246]),\n",
       "   '(0.095, 0.1]': array([0.23555986, 0.22620051]),\n",
       "   '(0.1, 0.105]': array([0.00161342, 0.00294861]),\n",
       "   '(0.105, 0.11]': array([0.01290739, 0.00800337]),\n",
       "   '(0.11, 0.115]': array([0.01000323, 0.00758214]),\n",
       "   '(0.115, 0.12]': array([0.01936108, 0.01979781]),\n",
       "   '(0.12, 0.125]': array([0.01193934, 0.00294861]),\n",
       "   '(0.125, 0.13]': array([0.00742175, 0.00547599]),\n",
       "   '(0.13, 0.135]': array([0.01097128, 0.01095198]),\n",
       "   '(0.135, 0.14]': array([0.02904163, 0.02148273]),\n",
       "   '(0.14, 0.145]': array([0.00258148, 0.00126369]),\n",
       "   '(0.145, 0.15]': array([0.14940303, 0.14953665]),\n",
       "   '(0.15, 0.155]': array([0.00968054, 0.01053075]),\n",
       "   '(0.155, 0.16]': array([0.02839626, 0.02737995]),\n",
       "   '(0.16, 0.165]': array([0.0083898, 0.0126369]),\n",
       "   '(0.165, 0.17]': array([0.0232333 , 0.02737995]),\n",
       "   '(0.17, 0.175]': array([0.00580833, 0.0126369 ]),\n",
       "   '(0.175, 0.18]': array([0.03259116, 0.02906487]),\n",
       "   '(0.18, 0.185]': array([0.00354953, 0.01347936]),\n",
       "   '(0.185, 0.19]': array([0.00774443, 0.00716091]),\n",
       "   '(0.19, 0.195]': array([0.00193611, 0.02021904]),\n",
       "   '(0.195, 0.2]': array([0.05453372, 0.07455771]),\n",
       "   '(0.2, 0.205]': array([0.00161342, 0.00210615]),\n",
       "   '(0.205, 0.21]': array([0.00387222, 0.00210615]),\n",
       "   '(0.22, 0.225]': array([0.00129074, 0.00252738]),\n",
       "   '(0.245, 0.25]': array([0.00225879, 0.00589722]),\n",
       "   '(0.295, 0.3]': array([0.00484027, 0.00042123]),\n",
       "   '(0.355, 0.36]': array([0.00161342, 0.00126369])},\n",
       "  'pref_o_shared_interests': {'(-0.001, 0.005]': array([0.08267974, 0.08736617]),\n",
       "   '(0.005, 0.01]': array([0.00620915, 0.00813704]),\n",
       "   '(0.015, 0.02]': array([0.00065359, 0.00299786]),\n",
       "   '(0.02, 0.025]': array([0.00326797, 0.00385439]),\n",
       "   '(0.025, 0.03]': array([0.00490196, 0.00214133]),\n",
       "   '(0.035, 0.04]': array([0.00359477, 0.0012848 ]),\n",
       "   '(0.045, 0.05]': array([0.11176471, 0.11862955]),\n",
       "   '(0.055, 0.06]': array([0.00392157, 0.00642398]),\n",
       "   '(0.06, 0.065]': array([0.00196078, 0.0012848 ]),\n",
       "   '(0.065, 0.07]': array([0.00228758, 0.00385439]),\n",
       "   '(0.07, 0.075]': array([0.00163399, 0.00085653]),\n",
       "   '(0.075, 0.08]': array([0.01339869, 0.0137045 ]),\n",
       "   '(0.08, 0.085]': array([0.00130719, 0.00299786]),\n",
       "   '(0.085, 0.09]': array([0.00457516, 0.00085653]),\n",
       "   '(0.09, 0.095]': array([0.0003268 , 0.00171306]),\n",
       "   '(0.095, 0.1]': array([0.2245098 , 0.25524625]),\n",
       "   '(0.1, 0.105]': array([0.00130719, 0.00256959]),\n",
       "   '(0.105, 0.11]': array([0.00816993, 0.00685225]),\n",
       "   '(0.11, 0.115]': array([0.00816993, 0.00385439]),\n",
       "   '(0.115, 0.12]': array([0.02614379, 0.02312634]),\n",
       "   '(0.12, 0.125]': array([0.00980392, 0.00942184]),\n",
       "   '(0.125, 0.13]': array([0.00816993, 0.00813704]),\n",
       "   '(0.13, 0.135]': array([0.00915033, 0.0261242 ]),\n",
       "   '(0.135, 0.14]': array([0.02156863, 0.02055675]),\n",
       "   '(0.14, 0.145]': array([0.00424837, 0.00513919]),\n",
       "   '(0.145, 0.15]': array([0.11764706, 0.13618844]),\n",
       "   '(0.15, 0.155]': array([0.02026144, 0.01456103]),\n",
       "   '(0.155, 0.16]': array([0.03594771, 0.02655246]),\n",
       "   '(0.16, 0.165]': array([0.00653595, 0.01327623]),\n",
       "   '(0.165, 0.17]': array([0.01339869, 0.00942184]),\n",
       "   '(0.17, 0.175]': array([0.00915033, 0.02055675]),\n",
       "   '(0.175, 0.18]': array([0.02581699, 0.02226981]),\n",
       "   '(0.18, 0.185]': array([0.00261438, 0.0012848 ]),\n",
       "   '(0.185, 0.19]': array([0.01339869, 0.00299786]),\n",
       "   '(0.19, 0.195]': array([0.00490196, 0.0012848 ]),\n",
       "   '(0.195, 0.2]': array([0.12810458, 0.10920771]),\n",
       "   '(0.205, 0.21]': array([0.00947712, 0.00299786]),\n",
       "   '(0.21, 0.215]': array([0.00163399, 0.00385439]),\n",
       "   '(0.215, 0.22]': array([0.01045752, 0.00556745]),\n",
       "   '(0.22, 0.225]': array([0.00130719, 0.0012848 ]),\n",
       "   '(0.235, 0.24]': array([0.00424837, 0.00042827]),\n",
       "   '(0.245, 0.25]': array([0.01633987, 0.00513919]),\n",
       "   '(0.295, 0.3]': array([0.01503268, 0.00599572])},\n",
       "  'attractive_important': {'(-0.001, 0.005]': array([0.0038548 , 0.00251256]),\n",
       "   '(0.045, 0.05]': array([0.00738837, 0.00502513]),\n",
       "   '(0.065, 0.07]': array([0.0038548 , 0.00586265]),\n",
       "   '(0.07, 0.075]': array([0.0019274 , 0.00628141]),\n",
       "   '(0.075, 0.08]': array([0.0019274 , 0.00502513]),\n",
       "   '(0.08, 0.085]': array([0.00064247, 0.00167504]),\n",
       "   '(0.085, 0.09]': array([0.00256987, 0.00251256]),\n",
       "   '(0.09, 0.095]': array([0.00032123, 0.00460637]),\n",
       "   '(0.095, 0.1]': array([0.09283649, 0.09463987]),\n",
       "   '(0.105, 0.11]': array([0.0019274 , 0.00460637]),\n",
       "   '(0.11, 0.115]': array([0.0048185 , 0.00544389]),\n",
       "   '(0.115, 0.12]': array([0.01445551, 0.00921273]),\n",
       "   '(0.12, 0.125]': array([0.00128493, 0.00251256]),\n",
       "   '(0.125, 0.13]': array([0.00160617, 0.00041876]),\n",
       "   '(0.13, 0.135]': array([0.00160617, 0.00251256]),\n",
       "   '(0.135, 0.14]': array([0.01798908, 0.01549414]),\n",
       "   '(0.14, 0.145]': array([0.00738837, 0.00879397]),\n",
       "   '(0.145, 0.15]': array([0.11596531, 0.11725293]),\n",
       "   '(0.15, 0.155]': array([0.03276582, 0.01423786]),\n",
       "   '(0.155, 0.16]': array([0.02345005, 0.02721943]),\n",
       "   '(0.16, 0.165]': array([0.00803084, 0.01046901]),\n",
       "   '(0.165, 0.17]': array([0.03276582, 0.02428811]),\n",
       "   '(0.17, 0.175]': array([0.01477674, 0.01926298]),\n",
       "   '(0.175, 0.18]': array([0.01831031, 0.01884422]),\n",
       "   '(0.18, 0.185]': array([0.0028911 , 0.00460637]),\n",
       "   '(0.185, 0.19]': array([0.01252811, 0.02135678]),\n",
       "   '(0.19, 0.195]': array([0.00321234, 0.00795645]),\n",
       "   '(0.195, 0.2]': array([0.19980726, 0.21147404]),\n",
       "   '(0.2, 0.205]': array([0.0019274, 0.0020938]),\n",
       "   '(0.205, 0.21]': array([0.01060071, 0.01716918]),\n",
       "   '(0.21, 0.215]': array([0.00642467, 0.00670017]),\n",
       "   '(0.215, 0.22]': array([0.01317058, 0.00293132]),\n",
       "   '(0.22, 0.225]': array([0.00128493, 0.00544389]),\n",
       "   '(0.225, 0.23]': array([0.0067459 , 0.00711893]),\n",
       "   '(0.235, 0.24]': array([0.00610344, 0.01172529]),\n",
       "   '(0.245, 0.25]': array([0.08673305, 0.09045226]),\n",
       "   '(0.255, 0.26]': array([0.00449727, 0.0020938 ]),\n",
       "   '(0.265, 0.27]': array([0.0038548 , 0.00251256]),\n",
       "   '(0.275, 0.28]': array([0.00321234, 0.00167504]),\n",
       "   '(0.295, 0.3]': array([0.09026662, 0.07537688]),\n",
       "   '(0.315, 0.32]': array([0.0028911 , 0.00335008]),\n",
       "   '(0.33, 0.335]': array([0.00224863, 0.00628141]),\n",
       "   '(0.345, 0.35]': array([0.02634115, 0.01884422]),\n",
       "   '(0.395, 0.4]': array([0.03501446, 0.03643216]),\n",
       "   '(0.445, 0.45]': array([0.00128493, 0.0020938 ]),\n",
       "   '(0.495, 0.5]': array([0.04240283, 0.03224456]),\n",
       "   '(0.545, 0.55]': array([0.00160617, 0.00335008]),\n",
       "   '(0.575, 0.58]': array([0.0038548 , 0.00251256]),\n",
       "   '(0.595, 0.6]': array([0.0048185 , 0.00460637]),\n",
       "   '(0.695, 0.7]': array([0.00449727, 0.00376884]),\n",
       "   '(0.745, 0.75]': array([0.00513974, 0.00502513]),\n",
       "   '(0.895, 0.9]': array([0.0019274 , 0.00167504]),\n",
       "   '(0.995, 1.0]': array([0.00224863, 0.00041876])},\n",
       "  'sincere_important': {'(-0.001, 0.005]': array([0.02578981, 0.02397981]),\n",
       "   '(0.015, 0.02]': array([0.00290135, 0.00336559]),\n",
       "   '(0.025, 0.03]': array([0.00515796, 0.00294489]),\n",
       "   '(0.045, 0.05]': array([0.04223082, 0.03239377]),\n",
       "   '(0.05, 0.055]': array([0.00257898, 0.00420698]),\n",
       "   '(0.065, 0.07]': array([0.00805932, 0.00546908]),\n",
       "   '(0.075, 0.08]': array([0.0035461 , 0.00210349]),\n",
       "   '(0.095, 0.1]': array([0.11605416, 0.1034918 ]),\n",
       "   '(0.105, 0.11]': array([0.00483559, 0.01262095]),\n",
       "   '(0.11, 0.115]': array([0.00451322, 0.00546908]),\n",
       "   '(0.115, 0.12]': array([0.00386847, 0.00168279]),\n",
       "   '(0.12, 0.125]': array([0.00161186, 0.00841397]),\n",
       "   '(0.125, 0.13]': array([0.00290135, 0.0008414 ]),\n",
       "   '(0.13, 0.135]': array([0.00838169, 0.00420698]),\n",
       "   '(0.135, 0.14]': array([0.00967118, 0.01009676]),\n",
       "   '(0.14, 0.145]': array([0.00161186, 0.00420698]),\n",
       "   '(0.145, 0.15]': array([0.13120567, 0.11611275]),\n",
       "   '(0.15, 0.155]': array([0.00386847, 0.00420698]),\n",
       "   '(0.155, 0.16]': array([0.0248227 , 0.01893143]),\n",
       "   '(0.16, 0.165]': array([0.01450677, 0.00757257]),\n",
       "   '(0.165, 0.17]': array([0.03481625, 0.02692469]),\n",
       "   '(0.17, 0.175]': array([0.0248227 , 0.02734539]),\n",
       "   '(0.175, 0.18]': array([0.05415861, 0.05427009]),\n",
       "   '(0.18, 0.185]': array([0.00676983, 0.01304165]),\n",
       "   '(0.185, 0.19]': array([0.01547389, 0.01262095]),\n",
       "   '(0.19, 0.195]': array([0.02450032, 0.0248212 ]),\n",
       "   '(0.195, 0.2]': array([0.2511283 , 0.26041228]),\n",
       "   '(0.2, 0.205]': array([0.00322373, 0.00673117]),\n",
       "   '(0.205, 0.21]': array([0.00773694, 0.01766933]),\n",
       "   '(0.21, 0.215]': array([0.00419084, 0.00673117]),\n",
       "   '(0.215, 0.22]': array([0.0035461 , 0.00631048]),\n",
       "   '(0.22, 0.225]': array([0.00580271, 0.00210349]),\n",
       "   '(0.225, 0.23]': array([0.00290135, 0.00504838]),\n",
       "   '(0.23, 0.235]': array([0.00128949, 0.0004207 ]),\n",
       "   '(0.235, 0.24]': array([0.00290135, 0.01514514]),\n",
       "   '(0.245, 0.25]': array([0.07607995, 0.07278082]),\n",
       "   '(0.255, 0.26]': array([0.00096712, 0.00294489]),\n",
       "   '(0.295, 0.3]': array([0.03900709, 0.04880101]),\n",
       "   '(0.315, 0.32]': array([0.00419084, 0.0012621 ]),\n",
       "   '(0.345, 0.35]': array([0.00612508, 0.00757257]),\n",
       "   '(0.395, 0.4]': array([0.00999355, 0.01177955]),\n",
       "   '(0.465, 0.47]': array([0.00225661, 0.00294489])},\n",
       "  'intelligence_important': {'(-0.001, 0.005]': array([0.00710136, 0.00758534]),\n",
       "   '(0.005, 0.01]': array([0.00129116, 0.00210704]),\n",
       "   '(0.015, 0.02]': array([0.00193673, 0.00168563]),\n",
       "   '(0.045, 0.05]': array([0.00774693, 0.01769912]),\n",
       "   '(0.075, 0.08]': array([0.00387347, 0.00252845]),\n",
       "   '(0.095, 0.1]': array([0.06584893, 0.06278972]),\n",
       "   '(0.1, 0.105]': array([0.00129116, 0.00126422]),\n",
       "   '(0.11, 0.115]': array([0.00193673, 0.00126422]),\n",
       "   '(0.145, 0.15]': array([0.087153  , 0.07669617]),\n",
       "   '(0.15, 0.155]': array([0.00710136, 0.00421408]),\n",
       "   '(0.155, 0.16]': array([0.02098128, 0.01264223]),\n",
       "   '(0.16, 0.165]': array([0.00516462, 0.00337126]),\n",
       "   '(0.165, 0.17]': array([0.02711427, 0.02275601]),\n",
       "   '(0.17, 0.175]': array([0.03066495, 0.01643489]),\n",
       "   '(0.175, 0.18]': array([0.05390575, 0.04804046]),\n",
       "   '(0.18, 0.185]': array([0.00968367, 0.00632111]),\n",
       "   '(0.185, 0.19]': array([0.02356359, 0.03329119]),\n",
       "   '(0.19, 0.195]': array([0.01775339, 0.01812052]),\n",
       "   '(0.195, 0.2]': array([0.33182699, 0.31099874]),\n",
       "   '(0.2, 0.205]': array([0.00419626, 0.00716393]),\n",
       "   '(0.205, 0.21]': array([0.01097482, 0.02612727]),\n",
       "   '(0.21, 0.215]': array([0.01032924, 0.01390645]),\n",
       "   '(0.215, 0.22]': array([0.00710136, 0.00842815]),\n",
       "   '(0.22, 0.225]': array([0.0087153 , 0.01601349]),\n",
       "   '(0.225, 0.23]': array([0.00613299, 0.00716393]),\n",
       "   '(0.23, 0.235]': array([0.00710136, 0.00800674]),\n",
       "   '(0.235, 0.24]': array([0.00322789, 0.01053519]),\n",
       "   '(0.245, 0.25]': array([0.09974177, 0.13105773]),\n",
       "   '(0.265, 0.27]': array([0.00193673, 0.00337126]),\n",
       "   '(0.27, 0.275]': array([0.00032279, 0.00463548]),\n",
       "   '(0.275, 0.28]': array([0.00677857, 0.0109566 ]),\n",
       "   '(0.295, 0.3]': array([0.08005165, 0.06784661]),\n",
       "   '(0.315, 0.32]': array([0.00193673, 0.00463548]),\n",
       "   '(0.345, 0.35]': array([0.02453196, 0.01011378]),\n",
       "   '(0.395, 0.4]': array([0.00677857, 0.01390645]),\n",
       "   '(0.425, 0.43]': array([0.00193673, 0.00252845]),\n",
       "   '(0.445, 0.45]': array([0.0058102 , 0.00294985]),\n",
       "   '(0.495, 0.5]': array([0.00645578, 0.00084282])},\n",
       "  'funny_important': {'(-0.001, 0.005]': array([0.00613101, 0.00126369]),\n",
       "   '(0.015, 0.02]': array([0.00193611, 0.00168492]),\n",
       "   '(0.025, 0.03]': array([0.00258148, 0.00252738]),\n",
       "   '(0.045, 0.05]': array([0.03065505, 0.03285594]),\n",
       "   '(0.075, 0.08]': array([0.00516296, 0.00505476]),\n",
       "   '(0.095, 0.1]': array([0.13843175, 0.15290649]),\n",
       "   '(0.1, 0.105]': array([0.00129074, 0.00126369]),\n",
       "   '(0.11, 0.115]': array([0.00193611, 0.00126369]),\n",
       "   '(0.115, 0.12]': array([0.01032591, 0.00716091]),\n",
       "   '(0.12, 0.125]': array([0.00387222, 0.00336984]),\n",
       "   '(0.125, 0.13]': array([0.00548564, 0.00926706]),\n",
       "   '(0.135, 0.14]': array([0.00677638, 0.0126369 ]),\n",
       "   '(0.14, 0.145]': array([0.00129074, 0.00252738]),\n",
       "   '(0.145, 0.15]': array([0.1565021 , 0.14448189]),\n",
       "   '(0.155, 0.16]': array([0.02904163, 0.02611626]),\n",
       "   '(0.16, 0.165]': array([0.00677638, 0.01221567]),\n",
       "   '(0.165, 0.17]': array([0.04194902, 0.03117102]),\n",
       "   '(0.17, 0.175]': array([0.02258793, 0.02021904]),\n",
       "   '(0.175, 0.18]': array([0.03969022, 0.04591407]),\n",
       "   '(0.18, 0.185]': array([0.01581155, 0.01095198]),\n",
       "   '(0.185, 0.19]': array([0.01871571, 0.01516428]),\n",
       "   '(0.19, 0.195]': array([0.0338819, 0.0252738]),\n",
       "   '(0.195, 0.2]': array([0.26137464, 0.23251896]),\n",
       "   '(0.2, 0.205]': array([0.00258148, 0.00547599]),\n",
       "   '(0.205, 0.21]': array([0.00451759, 0.0084246 ]),\n",
       "   '(0.21, 0.215]': array([0.00742175, 0.01727043]),\n",
       "   '(0.215, 0.22]': array([0.00613101, 0.01053075]),\n",
       "   '(0.22, 0.225]': array([0.00871249, 0.01811289]),\n",
       "   '(0.225, 0.23]': array([0.00516296, 0.01305813]),\n",
       "   '(0.23, 0.235]': array([0.00354953, 0.00336984]),\n",
       "   '(0.235, 0.24]': array([0.00484027, 0.00800337]),\n",
       "   '(0.245, 0.25]': array([0.06744111, 0.06950295]),\n",
       "   '(0.265, 0.27]': array([0.00129074, 0.00463353]),\n",
       "   '(0.27, 0.275]': array([0.00096805, 0.00168492]),\n",
       "   '(0.295, 0.3]': array([0.03291384, 0.02653749]),\n",
       "   '(0.345, 0.35]': array([0.00516296, 0.00379107]),\n",
       "   '(0.395, 0.4]': array([0.00322685, 0.00673968]),\n",
       "   '(0.445, 0.45]': array([0.00032268, 0.00252738]),\n",
       "   '(0.495, 0.5]': array([0.00354953, 0.00252738])},\n",
       "  'ambition_important': {'(-0.001, 0.005]': array([0.09640523, 0.08436831]),\n",
       "   '(0.005, 0.01]': array([0.00326797, 0.00385439]),\n",
       "   '(0.015, 0.02]': array([0.00555556, 0.01027837]),\n",
       "   '(0.02, 0.025]': array([0.00490196, 0.00899358]),\n",
       "   '(0.025, 0.03]': array([0.00849673, 0.00642398]),\n",
       "   '(0.035, 0.04]': array([0.00294118, 0.00171306]),\n",
       "   '(0.045, 0.05]': array([0.12418301, 0.15717345]),\n",
       "   '(0.055, 0.06]': array([0.00882353, 0.0124197 ]),\n",
       "   '(0.06, 0.065]': array([0.00228758, 0.00513919]),\n",
       "   '(0.065, 0.07]': array([0.00718954, 0.01156317]),\n",
       "   '(0.075, 0.08]': array([0.01797386, 0.01156317]),\n",
       "   '(0.085, 0.09]': array([0.00065359, 0.00256959]),\n",
       "   '(0.095, 0.1]': array([0.2503268 , 0.24111349]),\n",
       "   '(0.1, 0.105]': array([0.00424837, 0.00171306]),\n",
       "   '(0.105, 0.11]': array([0.01111111, 0.01498929]),\n",
       "   '(0.11, 0.115]': array([0.00588235, 0.00599572]),\n",
       "   '(0.115, 0.12]': array([0.01405229, 0.02269807]),\n",
       "   '(0.12, 0.125]': array([0.00294118, 0.01413276]),\n",
       "   '(0.125, 0.13]': array([0.00718954, 0.00471092]),\n",
       "   '(0.13, 0.135]': array([0.00915033, 0.0137045 ]),\n",
       "   '(0.135, 0.14]': array([0.01764706, 0.02655246]),\n",
       "   '(0.14, 0.145]': array([0.00163399, 0.00214133]),\n",
       "   '(0.145, 0.15]': array([0.16764706, 0.14561028]),\n",
       "   '(0.15, 0.155]': array([0.00849673, 0.00471092]),\n",
       "   '(0.155, 0.16]': array([0.02941176, 0.02055675]),\n",
       "   '(0.16, 0.165]': array([0.0127451 , 0.01156317]),\n",
       "   '(0.165, 0.17]': array([0.02777778, 0.01541756]),\n",
       "   '(0.17, 0.175]': array([0.00816993, 0.00513919]),\n",
       "   '(0.175, 0.18]': array([0.03300654, 0.02912206]),\n",
       "   '(0.18, 0.185]': array([0.00751634, 0.01070664]),\n",
       "   '(0.185, 0.19]': array([0.00947712, 0.00471092]),\n",
       "   '(0.19, 0.195]': array([0.01111111, 0.00942184]),\n",
       "   '(0.195, 0.2]': array([0.06503268, 0.0608137 ]),\n",
       "   '(0.2, 0.205]': array([0.00098039, 0.00214133]),\n",
       "   '(0.205, 0.21]': array([0.00294118, 0.00428266]),\n",
       "   '(0.22, 0.225]': array([0.00065359, 0.00342612]),\n",
       "   '(0.245, 0.25]': array([0.00653595, 0.00299786]),\n",
       "   '(0.295, 0.3]': array([0.00065359, 0.00471092]),\n",
       "   '(0.355, 0.36]': array([0.00098039, 0.00085653])},\n",
       "  'shared_interests_important': {'(-0.001, 0.005]': array([0.08636803, 0.07317073]),\n",
       "   '(0.005, 0.01]': array([0.0051563 , 0.00462574]),\n",
       "   '(0.015, 0.02]': array([0.00322269, 0.00252313]),\n",
       "   '(0.02, 0.025]': array([0.00354496, 0.00798991]),\n",
       "   '(0.025, 0.03]': array([0.00128908, 0.00630782]),\n",
       "   '(0.035, 0.04]': array([0.00418949, 0.00294365]),\n",
       "   '(0.045, 0.05]': array([0.10280374, 0.11690496]),\n",
       "   '(0.055, 0.06]': array([0.00354496, 0.00714886]),\n",
       "   '(0.06, 0.065]': array([0.00225588, 0.00294365]),\n",
       "   '(0.065, 0.07]': array([0.00386723, 0.00546678]),\n",
       "   '(0.07, 0.075]': array([0.00257815, 0.00168209]),\n",
       "   '(0.075, 0.08]': array([0.00966806, 0.01640034]),\n",
       "   '(0.08, 0.085]': array([0.00322269, 0.00168209]),\n",
       "   '(0.085, 0.09]': array([0.00257815, 0.00756939]),\n",
       "   '(0.09, 0.095]': array([0.00032227, 0.00462574]),\n",
       "   '(0.095, 0.1]': array([0.26780535, 0.22287637]),\n",
       "   '(0.1, 0.105]': array([0.00451176, 0.00210261]),\n",
       "   '(0.105, 0.11]': array([0.00741218, 0.01387721]),\n",
       "   '(0.11, 0.115]': array([0.00483403, 0.00714886]),\n",
       "   '(0.115, 0.12]': array([0.03190461, 0.02817494]),\n",
       "   '(0.12, 0.125]': array([0.00708991, 0.01513877]),\n",
       "   '(0.125, 0.13]': array([0.01063487, 0.00714886]),\n",
       "   '(0.13, 0.135]': array([0.02223655, 0.01387721]),\n",
       "   '(0.135, 0.14]': array([0.02449243, 0.01219512]),\n",
       "   '(0.14, 0.145]': array([0.00225588, 0.01051304]),\n",
       "   '(0.145, 0.15]': array([0.14147599, 0.1118587 ]),\n",
       "   '(0.15, 0.155]': array([0.0103126 , 0.00925147]),\n",
       "   '(0.155, 0.16]': array([0.02674831, 0.03111859]),\n",
       "   '(0.16, 0.165]': array([0.01224621, 0.01135408]),\n",
       "   '(0.165, 0.17]': array([0.01353529, 0.00798991]),\n",
       "   '(0.17, 0.175]': array([0.01385756, 0.01219512]),\n",
       "   '(0.175, 0.18]': array([0.01482436, 0.03111859]),\n",
       "   '(0.18, 0.185]': array([0.00290042, 0.00210261]),\n",
       "   '(0.185, 0.19]': array([0.00612311, 0.01387721]),\n",
       "   '(0.19, 0.195]': array([0.00741218, 0.00042052]),\n",
       "   '(0.195, 0.2]': array([0.10570416, 0.11942809]),\n",
       "   '(0.205, 0.21]': array([0.00612311, 0.01009251]),\n",
       "   '(0.21, 0.215]': array([0.00257815, 0.00462574]),\n",
       "   '(0.215, 0.22]': array([0.00451176, 0.00252313]),\n",
       "   '(0.22, 0.225]': array([0.00193361, 0.00126156]),\n",
       "   '(0.235, 0.24]': array([0.00161134, 0.00462574]),\n",
       "   '(0.245, 0.25]': array([0.00612311, 0.01471825]),\n",
       "   '(0.295, 0.3]': array([0.00418949, 0.01640034])},\n",
       "  'attractive': {'(1.95, 2.0]': array([0.00098039, 0.00513919]),\n",
       "   '(2.95, 3.0]': array([0.01372549, 0.01841542]),\n",
       "   '(3.95, 4.0]': array([0.01993464, 0.03297645]),\n",
       "   '(4.95, 5.0]': array([0.07941176, 0.09079229]),\n",
       "   '(5.95, 6.0]': array([0.12352941, 0.1503212 ]),\n",
       "   '(6.95, 7.0]': array([0.34934641, 0.34132762]),\n",
       "   '(7.95, 8.0]': array([0.28006536, 0.23640257]),\n",
       "   '(8.95, 9.0]': array([0.10196078, 0.08222698]),\n",
       "   '(9.95, 10.0]': array([0.03104575, 0.04239829])},\n",
       "  'sincere': {'(1.95, 2.0]': array([0.00620915, 0.00428266]),\n",
       "   '(2.95, 3.0]': array([0.00359477, 0.00471092]),\n",
       "   '(3.95, 4.0]': array([0.00915033, 0.01970021]),\n",
       "   '(4.95, 5.0]': array([0.02320261, 0.01841542]),\n",
       "   '(5.95, 6.0]': array([0.04509804, 0.0608137 ]),\n",
       "   '(6.95, 7.0]': array([0.14248366, 0.15631692]),\n",
       "   '(7.95, 8.0]': array([0.26568627, 0.23683084]),\n",
       "   '(8.95, 9.0]': array([0.27843137, 0.28736617]),\n",
       "   '(9.95, 10.0]': array([0.22614379, 0.21156317])},\n",
       "  'intelligence': {'(1.95, 2.0]': array([0.00424837, 0.00599572]),\n",
       "   '(2.95, 3.0]': array([0.01470588, 0.01327623]),\n",
       "   '(3.95, 4.0]': array([0.00849673, 0.02055675]),\n",
       "   '(4.95, 5.0]': array([0.05424837, 0.03768737]),\n",
       "   '(5.95, 6.0]': array([0.09934641, 0.1130621 ]),\n",
       "   '(6.95, 7.0]': array([0.2130719 , 0.20856531]),\n",
       "   '(7.95, 8.0]': array([0.25686275, 0.26509636]),\n",
       "   '(8.95, 9.0]': array([0.23235294, 0.20342612]),\n",
       "   '(9.95, 10.0]': array([0.11666667, 0.13233405])},\n",
       "  'funny': {'(2.95, 3.0]': array([0.00196078, 0.0012848 ]),\n",
       "   '(3.95, 4.0]': array([0.00065359, 0.00299786]),\n",
       "   '(4.95, 5.0]': array([0.01535948, 0.00599572]),\n",
       "   '(5.95, 6.0]': array([0.02058824, 0.0261242 ]),\n",
       "   '(6.95, 7.0]': array([0.1372549 , 0.10877944]),\n",
       "   '(7.95, 8.0]': array([0.34117647, 0.34304069]),\n",
       "   '(8.95, 9.0]': array([0.31960784, 0.3254818 ]),\n",
       "   '(9.95, 10.0]': array([0.16339869, 0.1862955 ])},\n",
       "  'ambition': {'(1.95, 2.0]': array([0.01176471, 0.01027837]),\n",
       "   '(2.95, 3.0]': array([0.01862745, 0.0261242 ]),\n",
       "   '(3.95, 4.0]': array([0.02745098, 0.02398287]),\n",
       "   '(4.95, 5.0]': array([0.07679739, 0.07366167]),\n",
       "   '(5.95, 6.0]': array([0.07385621, 0.09464668]),\n",
       "   '(6.95, 7.0]': array([0.20424837, 0.17259101]),\n",
       "   '(7.95, 8.0]': array([0.22973856, 0.248394  ]),\n",
       "   '(8.95, 9.0]': array([0.20392157, 0.19271949]),\n",
       "   '(9.95, 10.0]': array([0.15359477, 0.15760171])},\n",
       "  'attractive_partner': {'(-0.001, 0.05]': array([0.00195059, 0.00042535]),\n",
       "   '(0.95, 1.0]': array([0.02048114, 0.00297746]),\n",
       "   '(1.95, 2.0]': array([0.05039012, 0.00425351]),\n",
       "   '(2.95, 3.0]': array([0.08029909, 0.00723097]),\n",
       "   '(3.45, 3.5]': array([0.0006502 , 0.00042535]),\n",
       "   '(3.95, 4.0]': array([0.14369311, 0.02296895]),\n",
       "   '(4.95, 5.0]': array([0.2103381 , 0.07954062]),\n",
       "   '(5.95, 6.0]': array([0.23211964, 0.17099107]),\n",
       "   '(6.45, 6.5]': array([0.00097529, 0.00127605]),\n",
       "   '(6.95, 7.0]': array([0.1573472 , 0.25521055]),\n",
       "   '(7.45, 7.5]': array([0.0003251, 0.0017014]),\n",
       "   '(7.95, 8.0]': array([0.06827048, 0.25861336]),\n",
       "   '(8.95, 9.0]': array([0.02340702, 0.11909826]),\n",
       "   '(9.45, 9.5]': array([0.0006502, 0.0008507]),\n",
       "   '(9.85, 9.9]': array([0.0003251, 0.0008507]),\n",
       "   '(9.95, 10.0]': array([0.00877763, 0.07358571])},\n",
       "  'sincere_partner': {'(-0.001, 0.05]': array([0.00162707, 0.00042589]),\n",
       "   '(0.95, 1.0]': array([0.00683371, 0.00170358]),\n",
       "   '(1.95, 2.0]': array([0.0130166 , 0.00340716]),\n",
       "   '(2.95, 3.0]': array([0.02050114, 0.0076661 ]),\n",
       "   '(3.95, 4.0]': array([0.05304263, 0.01320273]),\n",
       "   '(4.95, 5.0]': array([0.10771233, 0.06005111]),\n",
       "   '(5.95, 6.0]': array([0.18288318, 0.12052811]),\n",
       "   '(6.95, 7.0]': array([0.22388545, 0.24361158]),\n",
       "   '(7.45, 7.5]': array([0.00032541, 0.00085179]),\n",
       "   '(7.95, 8.0]': array([0.22323462, 0.28918228]),\n",
       "   '(8.45, 8.5]': array([0.00032541, 0.00085179]),\n",
       "   '(8.95, 9.0]': array([0.09664823, 0.14906303]),\n",
       "   '(9.95, 10.0]': array([0.0699642 , 0.10945486])},\n",
       "  'intelligence_parter': {'(-0.001, 0.05]': array([0.00130039, 0.00042535]),\n",
       "   '(0.95, 1.0]': array([0.00325098, 0.00042535]),\n",
       "   '(1.95, 2.0]': array([0.00585176, 0.00042535]),\n",
       "   '(2.45, 2.5]': array([0.0006502 , 0.00042535]),\n",
       "   '(2.95, 3.0]': array([0.01170351, 0.00425351]),\n",
       "   '(3.95, 4.0]': array([0.03120936, 0.00510421]),\n",
       "   '(4.95, 5.0]': array([0.10338101, 0.0442365 ]),\n",
       "   '(5.95, 6.0]': array([0.17230169, 0.10676308]),\n",
       "   '(6.45, 6.5]': array([0.0003251, 0.0008507]),\n",
       "   '(6.95, 7.0]': array([0.25715215, 0.24287537]),\n",
       "   '(7.45, 7.5]': array([0.0006502 , 0.00127605]),\n",
       "   '(7.95, 8.0]': array([0.23244473, 0.31518503]),\n",
       "   '(8.45, 8.5]': array([0.0006502 , 0.00042535]),\n",
       "   '(8.95, 9.0]': array([0.10695709, 0.17524458]),\n",
       "   '(9.45, 9.5]': array([0.0006502 , 0.00042535]),\n",
       "   '(9.95, 10.0]': array([0.07152146, 0.10165887])},\n",
       "  'funny_partner': {'(-0.001, 0.05]': array([0.00227642, 0.00085106]),\n",
       "   '(0.95, 1.0]': array([0.02341463, 0.00170213]),\n",
       "   '(1.95, 2.0]': array([0.04357724, 0.00340426]),\n",
       "   '(2.95, 3.0]': array([0.05756098, 0.00723404]),\n",
       "   '(3.95, 4.0]': array([0.11707317, 0.01914894]),\n",
       "   '(4.95, 5.0]': array([0.1899187 , 0.08553191]),\n",
       "   '(5.45, 5.5]': array([0.00065041, 0.00042553]),\n",
       "   '(5.95, 6.0]': array([0.22276423, 0.16297872]),\n",
       "   '(6.45, 6.5]': array([0.00065041, 0.00085106]),\n",
       "   '(6.95, 7.0]': array([0.1700813, 0.2506383]),\n",
       "   '(7.45, 7.5]': array([0.0003252, 0.0012766]),\n",
       "   '(7.95, 8.0]': array([0.11154472, 0.26212766]),\n",
       "   '(8.95, 9.0]': array([0.03642276, 0.12425532]),\n",
       "   '(9.45, 9.5]': array([0.0003252 , 0.00085106]),\n",
       "   '(9.95, 10.0]': array([0.02341463, 0.0787234 ])},\n",
       "  'ambition_partner': {'(-0.001, 0.05]': array([0.00130166, 0.00042589]),\n",
       "   '(0.95, 1.0]': array([0.0087862 , 0.00042589]),\n",
       "   '(1.95, 2.0]': array([0.01919948, 0.00468484]),\n",
       "   '(2.95, 3.0]': array([0.02798568, 0.01149915]),\n",
       "   '(3.95, 4.0]': array([0.0654084, 0.0225724]),\n",
       "   '(4.95, 5.0]': array([0.16758868, 0.11456559]),\n",
       "   '(5.95, 6.0]': array([0.200781  , 0.17035775]),\n",
       "   '(6.95, 7.0]': array([0.20175724, 0.25298126]),\n",
       "   '(7.45, 7.5]': array([0.00032541, 0.00127768]),\n",
       "   '(7.95, 8.0]': array([0.17312073, 0.22018739]),\n",
       "   '(8.95, 9.0]': array([0.08395705, 0.12180579]),\n",
       "   '(9.45, 9.5]': array([0.00032541, 0.00085179]),\n",
       "   '(9.95, 10.0]': array([0.04946307, 0.07836457])},\n",
       "  'shared_interests_partner': {'(-0.001, 0.05]': array([0.01073171, 0.00340426]),\n",
       "   '(0.95, 1.0]': array([0.04747967, 0.00468085]),\n",
       "   '(1.95, 2.0]': array([0.10569106, 0.0187234 ]),\n",
       "   '(2.95, 3.0]': array([0.11707317, 0.02851064]),\n",
       "   '(3.95, 4.0]': array([0.14308943, 0.05361702]),\n",
       "   '(4.95, 5.0]': array([0.21723577, 0.18170213]),\n",
       "   '(5.45, 5.5]': array([0.0003252 , 0.00085106]),\n",
       "   '(5.95, 6.0]': array([0.16227642, 0.19319149]),\n",
       "   '(6.45, 6.5]': array([0.00065041, 0.00085106]),\n",
       "   '(6.95, 7.0]': array([0.10666667, 0.22340426]),\n",
       "   '(7.45, 7.5]': array([0.00065041, 0.00170213]),\n",
       "   '(7.95, 8.0]': array([0.05691057, 0.16680851]),\n",
       "   '(8.45, 8.5]': array([0.0003252 , 0.00085106]),\n",
       "   '(8.95, 9.0]': array([0.02146341, 0.07234043]),\n",
       "   '(9.95, 10.0]': array([0.00943089, 0.0493617 ])},\n",
       "  'sports': {'(0.95, 1.0]': array([0.03823529, 0.04411135]),\n",
       "   '(1.95, 2.0]': array([0.04444444, 0.07109208]),\n",
       "   '(2.95, 3.0]': array([0.07156863, 0.0856531 ]),\n",
       "   '(3.95, 4.0]': array([0.06895425, 0.05952891]),\n",
       "   '(4.95, 5.0]': array([0.09738562, 0.11520343]),\n",
       "   '(5.95, 6.0]': array([0.10686275, 0.08993576]),\n",
       "   '(6.95, 7.0]': array([0.15098039, 0.13576017]),\n",
       "   '(7.95, 8.0]': array([0.17026144, 0.15417559]),\n",
       "   '(8.95, 9.0]': array([0.11535948, 0.14261242]),\n",
       "   '(9.95, 10.0]': array([0.13594771, 0.10192719])},\n",
       "  'tvsports': {'(0.95, 1.0]': array([0.1879085 , 0.17730193]),\n",
       "   '(1.95, 2.0]': array([0.12679739, 0.15117773]),\n",
       "   '(2.95, 3.0]': array([0.10130719, 0.10877944]),\n",
       "   '(3.95, 4.0]': array([0.09215686, 0.07794433]),\n",
       "   '(4.95, 5.0]': array([0.10294118, 0.10278373]),\n",
       "   '(5.95, 6.0]': array([0.07843137, 0.08650964]),\n",
       "   '(6.95, 7.0]': array([0.11666667, 0.12376874]),\n",
       "   '(7.95, 8.0]': array([0.09346405, 0.07537473]),\n",
       "   '(8.95, 9.0]': array([0.05849673, 0.0496788 ]),\n",
       "   '(9.95, 10.0]': array([0.04183007, 0.04668094])},\n",
       "  'exercise': {'(0.95, 1.0]': array([0.03137255, 0.03768737]),\n",
       "   '(1.95, 2.0]': array([0.04575163, 0.08436831]),\n",
       "   '(2.95, 3.0]': array([0.06732026, 0.08351178]),\n",
       "   '(3.95, 4.0]': array([0.06993464, 0.06937901]),\n",
       "   '(4.95, 5.0]': array([0.11764706, 0.12119914]),\n",
       "   '(5.95, 6.0]': array([0.13398693, 0.13875803]),\n",
       "   '(6.95, 7.0]': array([0.15522876, 0.13961456]),\n",
       "   '(7.95, 8.0]': array([0.17124183, 0.16488223]),\n",
       "   '(8.95, 9.0]': array([0.11437908, 0.08479657]),\n",
       "   '(9.95, 10.0]': array([0.09313725, 0.075803  ])},\n",
       "  'dining': {'(0.95, 1.0]': array([0.00196078, 0.00856531]),\n",
       "   '(1.95, 2.0]': array([0.00098039, 0.00171306]),\n",
       "   '(2.95, 3.0]': array([0.00882353, 0.00899358]),\n",
       "   '(3.95, 4.0]': array([0.01405229, 0.02141328]),\n",
       "   '(4.95, 5.0]': array([0.08202614, 0.06466809]),\n",
       "   '(5.95, 6.0]': array([0.07745098, 0.11049251]),\n",
       "   '(6.95, 7.0]': array([0.18954248, 0.18158458]),\n",
       "   '(7.95, 8.0]': array([0.23169935, 0.22526767]),\n",
       "   '(8.95, 9.0]': array([0.20653595, 0.18843683]),\n",
       "   '(9.95, 10.0]': array([0.1869281, 0.1888651])},\n",
       "  'museums': {'(0.95, 1.0]': array([0.00751634, 0.00856531]),\n",
       "   '(1.95, 2.0]': array([0.00849673, 0.0111349 ]),\n",
       "   '(2.95, 3.0]': array([0.05359477, 0.04282655]),\n",
       "   '(3.95, 4.0]': array([0.05457516, 0.07066381]),\n",
       "   '(4.95, 5.0]': array([0.09803922, 0.09850107]),\n",
       "   '(5.95, 6.0]': array([0.1120915 , 0.10920771]),\n",
       "   '(6.95, 7.0]': array([0.22647059, 0.2012848 ]),\n",
       "   '(7.95, 8.0]': array([0.18267974, 0.19528908]),\n",
       "   '(8.95, 9.0]': array([0.14934641, 0.14475375]),\n",
       "   '(9.95, 10.0]': array([0.10718954, 0.11777302])},\n",
       "  'art': {'(0.95, 1.0]': array([0.01045752, 0.01498929]),\n",
       "   '(1.95, 2.0]': array([0.02418301, 0.01670236]),\n",
       "   '(2.95, 3.0]': array([0.07614379, 0.06552463]),\n",
       "   '(3.95, 4.0]': array([0.06437908, 0.07280514]),\n",
       "   '(4.95, 5.0]': array([0.12287582, 0.12119914]),\n",
       "   '(5.95, 6.0]': array([0.11372549, 0.10192719]),\n",
       "   '(6.95, 7.0]': array([0.16339869, 0.16531049]),\n",
       "   '(7.95, 8.0]': array([0.20620915, 0.20428266]),\n",
       "   '(8.95, 9.0]': array([0.10359477, 0.09764454]),\n",
       "   '(9.95, 10.0]': array([0.11503268, 0.13961456])},\n",
       "  'hiking': {'(-0.001, 0.05]': array([0.00228758, 0.00385439]),\n",
       "   '(0.95, 1.0]': array([0.04869281, 0.06124197]),\n",
       "   '(1.95, 2.0]': array([0.09084967, 0.07366167]),\n",
       "   '(2.95, 3.0]': array([0.12712418, 0.11220557]),\n",
       "   '(3.95, 4.0]': array([0.08660131, 0.08608137]),\n",
       "   '(4.95, 5.0]': array([0.11601307, 0.09421842]),\n",
       "   '(5.95, 6.0]': array([0.11045752, 0.14860814]),\n",
       "   '(6.95, 7.0]': array([0.13888889, 0.1254818 ]),\n",
       "   '(7.95, 8.0]': array([0.13954248, 0.14860814]),\n",
       "   '(8.95, 9.0]': array([0.08300654, 0.08008565]),\n",
       "   '(9.95, 10.0]': array([0.05653595, 0.06595289])},\n",
       "  'gaming': {'(-0.001, 0.05]': array([0.00555556, 0.00256959]),\n",
       "   '(0.95, 1.0]': array([0.26045752, 0.20428266]),\n",
       "   '(1.95, 2.0]': array([0.15490196, 0.12933619]),\n",
       "   '(2.95, 3.0]': array([0.13071895, 0.1366167 ]),\n",
       "   '(3.95, 4.0]': array([0.08823529, 0.0993576 ]),\n",
       "   '(4.95, 5.0]': array([0.12941176, 0.10492505]),\n",
       "   '(5.95, 6.0]': array([0.07320261, 0.11605996]),\n",
       "   '(6.95, 7.0]': array([0.08300654, 0.12248394]),\n",
       "   '(7.95, 8.0]': array([0.04019608, 0.04710921]),\n",
       "   '(8.95, 9.0]': array([0.02189542, 0.01884368]),\n",
       "   '(9.95, 10.0]': array([0.0124183 , 0.01841542])},\n",
       "  'clubbing': {'(0.95, 1.0]': array([0.10555556, 0.08779443]),\n",
       "   '(1.95, 2.0]': array([0.0369281, 0.0372591]),\n",
       "   '(2.95, 3.0]': array([0.0879085 , 0.08436831]),\n",
       "   '(3.95, 4.0]': array([0.08823529, 0.06295503]),\n",
       "   '(4.95, 5.0]': array([0.09738562, 0.11092077]),\n",
       "   '(5.95, 6.0]': array([0.13039216, 0.15760171]),\n",
       "   '(6.95, 7.0]': array([0.1620915 , 0.14732334]),\n",
       "   '(7.95, 8.0]': array([0.15947712, 0.17473233]),\n",
       "   '(8.95, 9.0]': array([0.12581699, 0.11777302]),\n",
       "   '(9.95, 10.0]': array([0.00620915, 0.01927195])},\n",
       "  'reading': {'(0.95, 1.0]': array([0.00098039, 0.0012848 ]),\n",
       "   '(1.95, 2.0]': array([0.02058824, 0.01456103]),\n",
       "   '(2.95, 3.0]': array([0.03137255, 0.02912206]),\n",
       "   '(3.95, 4.0]': array([0.03627451, 0.01884368]),\n",
       "   '(4.95, 5.0]': array([0.06601307, 0.0633833 ]),\n",
       "   '(5.95, 6.0]': array([0.08006536, 0.09850107]),\n",
       "   '(6.95, 7.0]': array([0.14771242, 0.15845824]),\n",
       "   '(7.95, 8.0]': array([0.19183007, 0.20171306]),\n",
       "   '(8.95, 9.0]': array([0.24771242, 0.22912206]),\n",
       "   '(9.95, 10.0]': array([0.17745098, 0.18501071])},\n",
       "  'tv': {'(0.95, 1.0]': array([0.09248366, 0.11605996]),\n",
       "   '(1.95, 2.0]': array([0.08366013, 0.0633833 ]),\n",
       "   '(2.95, 3.0]': array([0.07810458, 0.0732334 ]),\n",
       "   '(3.95, 4.0]': array([0.10653595, 0.10021413]),\n",
       "   '(4.95, 5.0]': array([0.1245098 , 0.14732334]),\n",
       "   '(5.95, 6.0]': array([0.16928105, 0.15246253]),\n",
       "   '(6.95, 7.0]': array([0.10784314, 0.14132762]),\n",
       "   '(7.95, 8.0]': array([0.12189542, 0.11520343]),\n",
       "   '(8.95, 9.0]': array([0.06732026, 0.05010707]),\n",
       "   '(9.95, 10.0]': array([0.04836601, 0.04068522])},\n",
       "  'theater': {'(0.95, 1.0]': array([0.01699346, 0.01627409]),\n",
       "   '(1.95, 2.0]': array([0.03039216, 0.02184154]),\n",
       "   '(2.95, 3.0]': array([0.05457516, 0.05139186]),\n",
       "   '(3.95, 4.0]': array([0.06764706, 0.06038544]),\n",
       "   '(4.95, 5.0]': array([0.10718954, 0.12205567]),\n",
       "   '(5.95, 6.0]': array([0.11764706, 0.13832976]),\n",
       "   '(6.95, 7.0]': array([0.19901961, 0.1738758 ]),\n",
       "   '(7.95, 8.0]': array([0.1379085 , 0.16102784]),\n",
       "   '(8.95, 9.0]': array([0.16699346, 0.13961456]),\n",
       "   '(9.95, 10.0]': array([0.10163399, 0.11520343])},\n",
       "  'movies': {'(1.95, 2.0]': array([0.01013072, 0.00385439]),\n",
       "   '(2.95, 3.0]': array([0.01013072, 0.02012848]),\n",
       "   '(3.95, 4.0]': array([0.0248366 , 0.01798715]),\n",
       "   '(4.95, 5.0]': array([0.04803922, 0.04796574]),\n",
       "   '(5.95, 6.0]': array([0.07875817, 0.08137045]),\n",
       "   '(6.95, 7.0]': array([0.16764706, 0.19957173]),\n",
       "   '(7.95, 8.0]': array([0.21764706, 0.24239829]),\n",
       "   '(8.95, 9.0]': array([0.24836601, 0.19785867]),\n",
       "   '(9.95, 10.0]': array([0.19444444, 0.1888651 ])},\n",
       "  'concerts': {'(0.95, 1.0]': array([0.00784314, 0.00856531]),\n",
       "   '(1.95, 2.0]': array([0.02647059, 0.02526767]),\n",
       "   '(2.95, 3.0]': array([0.0503268 , 0.05267666]),\n",
       "   '(3.95, 4.0]': array([0.0627451 , 0.06680942]),\n",
       "   '(4.95, 5.0]': array([0.1251634, 0.1006424]),\n",
       "   '(5.95, 6.0]': array([0.14052288, 0.14646681]),\n",
       "   '(6.95, 7.0]': array([0.18235294, 0.17173448]),\n",
       "   '(7.95, 8.0]': array([0.16928105, 0.14646681]),\n",
       "   '(8.95, 9.0]': array([0.14084967, 0.15888651]),\n",
       "   '(9.95, 10.0]': array([0.09444444, 0.12248394])},\n",
       "  'music': {'(0.95, 1.0]': array([0.0003268 , 0.00813704]),\n",
       "   '(1.95, 2.0]': array([0.00686275, 0.00342612]),\n",
       "   '(2.95, 3.0]': array([0.00228758, 0.00599572]),\n",
       "   '(3.95, 4.0]': array([0.0251634, 0.0261242]),\n",
       "   '(4.95, 5.0]': array([0.06928105, 0.06552463]),\n",
       "   '(5.95, 6.0]': array([0.1003268, 0.0869379]),\n",
       "   '(6.95, 7.0]': array([0.18366013, 0.19957173]),\n",
       "   '(7.95, 8.0]': array([0.20588235, 0.17601713]),\n",
       "   '(8.95, 9.0]': array([0.19607843, 0.20642398]),\n",
       "   '(9.95, 10.0]': array([0.21013072, 0.22184154])},\n",
       "  'shopping': {'(0.95, 1.0]': array([0.05947712, 0.06167024]),\n",
       "   '(1.95, 2.0]': array([0.10130719, 0.11263383]),\n",
       "   '(2.95, 3.0]': array([0.06503268, 0.06680942]),\n",
       "   '(3.95, 4.0]': array([0.09313725, 0.08736617]),\n",
       "   '(4.95, 5.0]': array([0.12745098, 0.15246253]),\n",
       "   '(5.95, 6.0]': array([0.10457516, 0.12119914]),\n",
       "   '(6.95, 7.0]': array([0.15065359, 0.1379015 ]),\n",
       "   '(7.95, 8.0]': array([0.1      , 0.1006424]),\n",
       "   '(8.95, 9.0]': array([0.11830065, 0.0869379 ]),\n",
       "   '(9.95, 10.0]': array([0.08006536, 0.07237687])},\n",
       "  'yoga': {'(-0.001, 0.05]': array([0.00392157, 0.00042827]),\n",
       "   '(0.95, 1.0]': array([0.19084967, 0.2137045 ]),\n",
       "   '(1.95, 2.0]': array([0.15098039, 0.11349036]),\n",
       "   '(2.95, 3.0]': array([0.12647059, 0.12334047]),\n",
       "   '(3.95, 4.0]': array([0.08823529, 0.06552463]),\n",
       "   '(4.95, 5.0]': array([0.09313725, 0.11734475]),\n",
       "   '(5.95, 6.0]': array([0.10130719, 0.09807281]),\n",
       "   '(6.95, 7.0]': array([0.10653595, 0.09850107]),\n",
       "   '(7.95, 8.0]': array([0.05      , 0.06466809]),\n",
       "   '(8.95, 9.0]': array([0.05098039, 0.05610278]),\n",
       "   '(9.95, 10.0]': array([0.0375817 , 0.04882227])},\n",
       "  'interests_correlate': {'(-0.01, 0.0]': array([0.01903276, 0.01774194]),\n",
       "   '(-0.02, -0.01]': array([0.00873635, 0.00846774]),\n",
       "   '(-0.03, -0.02]': array([0.00655226, 0.00887097]),\n",
       "   '(-0.04, -0.03]': array([0.00936037, 0.00806452]),\n",
       "   '(-0.06, -0.05]': array([0.0099844 , 0.01129032]),\n",
       "   '(-0.07, -0.06]': array([0.00842434, 0.01290323]),\n",
       "   '(-0.08, -0.07]': array([0.01029641, 0.00685484]),\n",
       "   '(-0.09, -0.08]': array([0.00717629, 0.00483871]),\n",
       "   '(-0.1, -0.09]': array([0.00592824, 0.00846774]),\n",
       "   '(-0.11, -0.1]': array([0.00436817, 0.00604839]),\n",
       "   '(-0.12, -0.11]': array([0.0074883 , 0.00524194]),\n",
       "   '(-0.13, -0.12]': array([0.00655226, 0.00645161]),\n",
       "   '(-0.14, -0.13]': array([0.00655226, 0.00443548]),\n",
       "   '(-0.15, -0.14]': array([0.01622465, 0.01491935]),\n",
       "   '(-0.16, -0.15]': array([0.00717629, 0.00685484]),\n",
       "   '(-0.18, -0.17]': array([0.00312012, 0.00766129]),\n",
       "   '(-0.19, -0.18]': array([0.00842434, 0.00604839]),\n",
       "   '(-0.2, -0.19]': array([0.0074883 , 0.00725806]),\n",
       "   '(-0.21, -0.2]': array([0.00780031, 0.00524194]),\n",
       "   '(-0.22, -0.21]': array([0.0049922 , 0.00564516]),\n",
       "   '(-0.23, -0.22]': array([0.00811232, 0.00725806]),\n",
       "   '(-0.24, -0.23]': array([0.00592824, 0.00564516]),\n",
       "   '(-0.25, -0.24]': array([0.00468019, 0.00604839]),\n",
       "   '(-0.26, -0.25]': array([0.00592824, 0.00443548]),\n",
       "   '(-0.27, -0.26]': array([0.00405616, 0.00322581]),\n",
       "   '(-0.28, -0.27]': array([0.00561622, 0.00604839]),\n",
       "   '(-0.29, -0.28]': array([0.00873635, 0.00725806]),\n",
       "   '(-0.31, -0.3]': array([0.00624025, 0.00282258]),\n",
       "   '(-0.32, -0.31]': array([0.00468019, 0.00241935]),\n",
       "   '(-0.33, -0.32]': array([0.0024961 , 0.00403226]),\n",
       "   '(-0.34, -0.33]': array([0.0024961 , 0.00362903]),\n",
       "   '(-0.35, -0.34]': array([0.00530421, 0.00403226]),\n",
       "   '(-0.36, -0.35]': array([0.00280811, 0.00443548]),\n",
       "   '(-0.37, -0.36]': array([0.00405616, 0.00483871]),\n",
       "   '(-0.38, -0.37]': array([0.00312012, 0.00362903]),\n",
       "   '(-0.39, -0.38]': array([0.00374415, 0.00362903]),\n",
       "   '(-0.4, -0.39]': array([0.0024961, 0.0016129]),\n",
       "   '(-0.41, -0.4]': array([0.00780031, 0.00524194]),\n",
       "   '(-0.42, -0.41]': array([0.00124805, 0.00120968]),\n",
       "   '(-0.44, -0.43]': array([0.00343214, 0.00241935]),\n",
       "   '(-0.45, -0.44]': array([0.00124805, 0.00201613]),\n",
       "   '(-0.46, -0.45]': array([0.00187207, 0.00080645]),\n",
       "   '(-0.47, -0.46]': array([0.00312012, 0.00241935]),\n",
       "   '(-0.48, -0.47]': array([0.00156006, 0.00443548]),\n",
       "   '(-0.49, -0.48]': array([0.00062402, 0.00080645]),\n",
       "   '(-0.51, -0.5]': array([0.00218409, 0.00282258]),\n",
       "   '(-0.52, -0.51]': array([0.00187207, 0.00120968]),\n",
       "   '(-0.53, -0.52]': array([0.0024961 , 0.00120968]),\n",
       "   '(-0.56, -0.55]': array([0.00062402, 0.00080645]),\n",
       "   '(-0.57, -0.56]': array([0.00156006, 0.00120968]),\n",
       "   '(-0.58, -0.57]': array([0.00093604, 0.00120968]),\n",
       "   '(-0.6, -0.59]': array([0.00062402, 0.0016129 ]),\n",
       "   '(-0.62, -0.61]': array([0.00124805, 0.00040323]),\n",
       "   '(-0.63, -0.62]': array([0.00062402, 0.00040323]),\n",
       "   '(-0.64, -0.63]': array([0.00124805, 0.00080645]),\n",
       "   '(-0.65, -0.64]': array([0.00093604, 0.00040323]),\n",
       "   '(-0.71, -0.7]': array([0.00062402, 0.00040323]),\n",
       "   '(-0.74, -0.73]': array([0.00093604, 0.00040323]),\n",
       "   '(-0.84, -0.83]': array([0.00031201, 0.00080645]),\n",
       "   '(0.0, 0.01]': array([0.0074883 , 0.00967742]),\n",
       "   '(0.01, 0.02]': array([0.00904836, 0.01008065]),\n",
       "   '(0.02, 0.03]': array([0.0099844 , 0.00967742]),\n",
       "   '(0.03, 0.04]': array([0.00873635, 0.00645161]),\n",
       "   '(0.04, 0.05]': array([0.00967239, 0.00887097]),\n",
       "   '(0.05, 0.06]': array([0.00561622, 0.01008065]),\n",
       "   '(0.06, 0.07]': array([0.01185647, 0.00766129]),\n",
       "   '(0.07, 0.08]': array([0.01185647, 0.01612903]),\n",
       "   '(0.08, 0.09]': array([0.01123245, 0.01491935]),\n",
       "   '(0.09, 0.1]': array([0.00967239, 0.01129032]),\n",
       "   '(0.1, 0.11]': array([0.01435257, 0.01048387]),\n",
       "   '(0.11, 0.12]': array([0.01123245, 0.01209677]),\n",
       "   '(0.12, 0.13]': array([0.01560062, 0.01169355]),\n",
       "   '(0.13, 0.14]': array([0.01372855, 0.01169355]),\n",
       "   '(0.14, 0.15]': array([0.01092044, 0.00927419]),\n",
       "   '(0.16, 0.17]': array([0.01123245, 0.00967742]),\n",
       "   '(0.17, 0.18]': array([0.00904836, 0.01290323]),\n",
       "   '(0.18, 0.19]': array([0.01185647, 0.00806452]),\n",
       "   '(0.19, 0.2]': array([0.01372855, 0.01330645]),\n",
       "   '(0.2, 0.21]': array([0.00967239, 0.00645161]),\n",
       "   '(0.21, 0.22]': array([0.01123245, 0.01129032]),\n",
       "   '(0.22, 0.23]': array([0.00904836, 0.00927419]),\n",
       "   '(0.23, 0.24]': array([0.02308892, 0.02419355]),\n",
       "   '(0.24, 0.25]': array([0.01092044, 0.00846774]),\n",
       "   '(0.25, 0.26]': array([0.01185647, 0.01209677]),\n",
       "   '(0.26, 0.27]': array([0.01216849, 0.00927419]),\n",
       "   '(0.27, 0.28]': array([0.00842434, 0.01129032]),\n",
       "   '(0.28, 0.29]': array([0.01154446, 0.0108871 ]),\n",
       "   '(0.29, 0.3]': array([0.00873635, 0.00887097]),\n",
       "   '(0.3, 0.31]': array([0.01716069, 0.01774194]),\n",
       "   '(0.31, 0.32]': array([0.01154446, 0.0125    ]),\n",
       "   '(0.32, 0.33]': array([0.01154446, 0.0108871 ]),\n",
       "   '(0.33, 0.34]': array([0.01372855, 0.0125    ]),\n",
       "   '(0.34, 0.35]': array([0.01185647, 0.00927419]),\n",
       "   '(0.35, 0.36]': array([0.0099844 , 0.01290323]),\n",
       "   '(0.36, 0.37]': array([0.00936037, 0.01048387]),\n",
       "   '(0.37, 0.38]': array([0.01185647, 0.00927419]),\n",
       "   '(0.38, 0.39]': array([0.00873635, 0.00887097]),\n",
       "   '(0.39, 0.4]': array([0.01154446, 0.01129032]),\n",
       "   '(0.41, 0.42]': array([0.0124805 , 0.01169355]),\n",
       "   '(0.42, 0.43]': array([0.00811232, 0.01169355]),\n",
       "   '(0.43, 0.44]': array([0.01372855, 0.01572581]),\n",
       "   '(0.44, 0.45]': array([0.01154446, 0.00927419]),\n",
       "   '(0.45, 0.46]': array([0.01216849, 0.00806452]),\n",
       "   '(0.46, 0.47]': array([0.01965679, 0.01814516]),\n",
       "   '(0.47, 0.48]': array([0.00904836, 0.0125    ]),\n",
       "   '(0.48, 0.49]': array([0.0074883 , 0.00887097]),\n",
       "   '(0.49, 0.5]': array([0.01154446, 0.01008065]),\n",
       "   '(0.5, 0.51]': array([0.00904836, 0.00887097]),\n",
       "   '(0.51, 0.52]': array([0.00936037, 0.01129032]),\n",
       "   '(0.52, 0.53]': array([0.01029641, 0.0141129 ]),\n",
       "   '(0.53, 0.54]': array([0.0124805 , 0.01008065]),\n",
       "   '(0.54, 0.55]': array([0.00811232, 0.00685484]),\n",
       "   '(0.55, 0.56]': array([0.00561622, 0.00846774]),\n",
       "   '(0.56, 0.57]': array([0.00436817, 0.00604839]),\n",
       "   '(0.57, 0.58]': array([0.00686427, 0.00524194]),\n",
       "   '(0.58, 0.59]': array([0.00904836, 0.01048387]),\n",
       "   '(0.59, 0.6]': array([0.00717629, 0.01008065]),\n",
       "   '(0.6, 0.61]': array([0.00468019, 0.00766129]),\n",
       "   '(0.61, 0.62]': array([0.00686427, 0.00967742]),\n",
       "   '(0.62, 0.63]': array([0.00405616, 0.00645161]),\n",
       "   '(0.63, 0.64]': array([0.00842434, 0.00645161]),\n",
       "   '(0.64, 0.65]': array([0.00904836, 0.01008065]),\n",
       "   '(0.65, 0.66]': array([0.00561622, 0.00362903]),\n",
       "   '(0.67, 0.68]': array([0.00343214, 0.00403226]),\n",
       "   '(0.68, 0.69]': array([0.00873635, 0.00604839]),\n",
       "   '(0.69, 0.7]': array([0.00280811, 0.00282258]),\n",
       "   '(0.7, 0.71]': array([0.0024961 , 0.00564516]),\n",
       "   '(0.71, 0.72]': array([0.00561622, 0.00685484]),\n",
       "   '(0.72, 0.73]': array([0.00312012, 0.00564516]),\n",
       "   '(0.73, 0.74]': array([0.0049922 , 0.00282258]),\n",
       "   '(0.74, 0.75]': array([0.00156006, 0.00282258]),\n",
       "   '(0.75, 0.76]': array([0.00093604, 0.00362903]),\n",
       "   '(0.76, 0.77]': array([0.00156006, 0.0016129 ]),\n",
       "   '(0.77, 0.78]': array([0.00156006, 0.00201613]),\n",
       "   '(0.78, 0.79]': array([0.00093604, 0.0016129 ]),\n",
       "   '(0.79, 0.8]': array([0.0024961 , 0.00201613]),\n",
       "   '(0.8, 0.81]': array([0.00124805, 0.00120968]),\n",
       "   '(0.81, 0.82]': array([0.00031201, 0.00080645]),\n",
       "   '(0.82, 0.83]': array([0.0024961 , 0.00080645]),\n",
       "   '(0.83, 0.84]': array([0.00062402, 0.00080645]),\n",
       "   '(0.84, 0.85]': array([0.00124805, 0.00120968]),\n",
       "   '(0.86, 0.87]': array([0.00062402, 0.00040323]),\n",
       "   '(0.87, 0.88]': array([0.00062402, 0.00040323]),\n",
       "   '(0.89, 0.9]': array([0.00093604, 0.00120968]),\n",
       "   '(0.9, 0.91]': array([0.00062402, 0.00080645])},\n",
       "  'expected_happy_with_sd_people': {'(0.95, 1.0]': array([0.02124183, 0.00985011]),\n",
       "   '(1.95, 2.0]': array([0.03496732, 0.02997859]),\n",
       "   '(2.95, 3.0]': array([0.10882353, 0.07494647]),\n",
       "   '(3.95, 4.0]': array([0.10065359, 0.09207709]),\n",
       "   '(4.95, 5.0]': array([0.25359477, 0.22398287]),\n",
       "   '(5.95, 6.0]': array([0.2245098 , 0.26124197]),\n",
       "   '(6.95, 7.0]': array([0.16535948, 0.19014989]),\n",
       "   '(7.95, 8.0]': array([0.05882353, 0.06809422]),\n",
       "   '(8.95, 9.0]': array([0.02156863, 0.02955032]),\n",
       "   '(9.95, 10.0]': array([0.01045752, 0.02012848])},\n",
       "  'like': {'(-0.001, 0.05]': array([0.00162443, 0.00042499]),\n",
       "   '(0.95, 1.0]': array([0.02046784, 0.00127497]),\n",
       "   '(1.95, 2.0]': array([0.04873294, 0.00169996]),\n",
       "   '(2.95, 3.0]': array([0.08414555, 0.00424989]),\n",
       "   '(3.95, 4.0]': array([0.12897986, 0.01232469]),\n",
       "   '(4.45, 4.5]': array([0.00032489, 0.00084998]),\n",
       "   '(4.95, 5.0]': array([0.23326836, 0.06119847]),\n",
       "   '(5.45, 5.5]': array([0.00032489, 0.00084998]),\n",
       "   '(5.95, 6.0]': array([0.23846654, 0.18912027]),\n",
       "   '(6.45, 6.5]': array([0.00129955, 0.00424989]),\n",
       "   '(6.95, 7.0]': array([0.15367122, 0.30429239]),\n",
       "   '(7.45, 7.5]': array([0.00064977, 0.00169996]),\n",
       "   '(7.95, 8.0]': array([0.06562703, 0.27241819]),\n",
       "   '(8.45, 8.5]': array([0.00064977, 0.00254994]),\n",
       "   '(8.95, 9.0]': array([0.01526966, 0.09732257]),\n",
       "   '(9.45, 9.5]': array([0.00032489, 0.00169996]),\n",
       "   '(9.65, 9.7]': array([0.00064977, 0.00042499]),\n",
       "   '(9.95, 10.0]': array([0.00552307, 0.04334892])}},\n",
       "       gender           age         age_o  race  race_o  samerace  \\\n",
       " 5348       1  (27.8, 28.0]  (21.8, 22.0]     2       2         1   \n",
       " 1225       0  (25.8, 26.0]  (22.8, 23.0]     0       2         0   \n",
       " 4424       0  (28.8, 29.0]  (22.8, 23.0]     0       2         0   \n",
       " 1338       1  (22.8, 23.0]  (30.8, 31.0]     2       2         1   \n",
       " 227        0  (22.8, 23.0]  (22.8, 23.0]     1       2         0   \n",
       " ...      ...           ...           ...   ...     ...       ...   \n",
       " 2896       1  (27.8, 28.0]  (23.8, 24.0]     1       2         0   \n",
       " 691        1  (26.8, 27.0]  (28.8, 29.0]     2       2         1   \n",
       " 3336       0  (23.8, 24.0]  (29.8, 30.0]     2       0         0   \n",
       " 1926       1  (26.8, 27.0]  (29.8, 30.0]     2       2         1   \n",
       " 5255       1  (23.8, 24.0]  (22.8, 23.0]     0       0         1   \n",
       " \n",
       "      importance_same_race importance_same_religion  field pref_o_attractive  \\\n",
       " 5348          (1.95, 2.0]              (2.95, 3.0]     89      (0.095, 0.1]   \n",
       " 1225          (2.95, 3.0]              (2.95, 3.0]     23     (0.19, 0.195]   \n",
       " 4424          (8.95, 9.0]              (7.95, 8.0]     23      (0.195, 0.2]   \n",
       " 1338          (2.95, 3.0]              (3.95, 4.0]    175     (0.115, 0.12]   \n",
       " 227           (7.95, 8.0]              (0.95, 1.0]    121     (0.245, 0.25]   \n",
       " ...                   ...                      ...    ...               ...   \n",
       " 2896          (6.95, 7.0]              (0.95, 1.0]    105      (0.195, 0.2]   \n",
       " 691           (5.95, 6.0]              (7.95, 8.0]     36     (0.135, 0.14]   \n",
       " 3336          (6.95, 7.0]              (5.95, 6.0]    165      (0.495, 0.5]   \n",
       " 1926          (6.95, 7.0]              (0.95, 1.0]    142     (0.17, 0.175]   \n",
       " 5255          (8.95, 9.0]              (5.95, 6.0]     70      (0.195, 0.2]   \n",
       " \n",
       "       ...      theater        movies      concerts         music  \\\n",
       " 5348  ...  (7.95, 8.0]   (7.95, 8.0]  (9.95, 10.0]  (9.95, 10.0]   \n",
       " 1225  ...  (8.95, 9.0]   (7.95, 8.0]   (5.95, 6.0]   (5.95, 6.0]   \n",
       " 4424  ...  (7.95, 8.0]   (7.95, 8.0]   (3.95, 4.0]   (0.95, 1.0]   \n",
       " 1338  ...  (4.95, 5.0]   (7.95, 8.0]   (3.95, 4.0]   (8.95, 9.0]   \n",
       " 227   ...  (7.95, 8.0]  (9.95, 10.0]  (9.95, 10.0]  (9.95, 10.0]   \n",
       " ...   ...          ...           ...           ...           ...   \n",
       " 2896  ...  (6.95, 7.0]   (8.95, 9.0]   (4.95, 5.0]  (9.95, 10.0]   \n",
       " 691   ...  (7.95, 8.0]   (6.95, 7.0]   (5.95, 6.0]   (7.95, 8.0]   \n",
       " 3336  ...  (6.95, 7.0]   (6.95, 7.0]   (7.95, 8.0]   (8.95, 9.0]   \n",
       " 1926  ...  (5.95, 6.0]   (6.95, 7.0]   (5.95, 6.0]   (4.95, 5.0]   \n",
       " 5255  ...  (5.95, 6.0]   (7.95, 8.0]   (7.95, 8.0]   (7.95, 8.0]   \n",
       " \n",
       "           shopping          yoga interests_correlate  \\\n",
       " 5348   (7.95, 8.0]   (1.95, 2.0]        (0.28, 0.29]   \n",
       " 1225   (6.95, 7.0]  (9.95, 10.0]      (-0.15, -0.14]   \n",
       " 4424  (9.95, 10.0]   (8.95, 9.0]      (-0.42, -0.41]   \n",
       " 1338   (4.95, 5.0]   (0.95, 1.0]         (0.3, 0.31]   \n",
       " 227   (9.95, 10.0]   (1.95, 2.0]       (-0.31, -0.3]   \n",
       " ...            ...           ...                 ...   \n",
       " 2896   (0.95, 1.0]   (0.95, 1.0]        (0.21, 0.22]   \n",
       " 691    (2.95, 3.0]   (6.95, 7.0]        (0.45, 0.46]   \n",
       " 3336   (5.95, 6.0]   (8.95, 9.0]      (-0.04, -0.03]   \n",
       " 1926   (1.95, 2.0]   (0.95, 1.0]         (0.3, 0.31]   \n",
       " 5255   (7.95, 8.0]   (2.95, 3.0]      (-0.34, -0.33]   \n",
       " \n",
       "      expected_happy_with_sd_people         like decision  \n",
       " 5348                   (4.95, 5.0]  (5.95, 6.0]        1  \n",
       " 1225                   (4.95, 5.0]  (4.95, 5.0]        0  \n",
       " 4424                   (4.95, 5.0]  (4.95, 5.0]        0  \n",
       " 1338                   (6.95, 7.0]  (8.95, 9.0]        1  \n",
       " 227                    (1.95, 2.0]  (6.95, 7.0]        0  \n",
       " ...                            ...          ...      ...  \n",
       " 2896                   (5.95, 6.0]  (4.95, 5.0]        0  \n",
       " 691                    (7.95, 8.0]  (6.95, 7.0]        1  \n",
       " 3336                   (5.95, 6.0]  (5.95, 6.0]        0  \n",
       " 1926                   (5.95, 6.0]  (6.95, 7.0]        1  \n",
       " 5255                   (7.95, 8.0]  (7.95, 8.0]        0  \n",
       " \n",
       " [5395 rows x 53 columns],\n",
       "       gender           age         age_o  race  race_o  samerace  \\\n",
       " 0          0  (25.8, 26.0]  (24.8, 25.0]     3       2         0   \n",
       " 1          0  (30.8, 31.0]  (26.8, 27.0]     2       2         1   \n",
       " 2          1  (26.8, 27.0]  (27.8, 28.0]     0       2         0   \n",
       " 3          0  (21.8, 22.0]  (27.8, 28.0]     2       2         1   \n",
       " 4          1  (26.8, 27.0]  (26.8, 27.0]     2       0         0   \n",
       " ...      ...           ...           ...   ...     ...       ...   \n",
       " 1344       1  (22.8, 23.0]  (23.8, 24.0]     1       2         0   \n",
       " 1345       0  (28.8, 29.0]  (30.8, 31.0]     0       0         1   \n",
       " 1346       1  (24.8, 25.0]  (29.8, 30.0]     0       3         0   \n",
       " 1347       0  (29.8, 30.0]  (27.8, 28.0]     3       2         0   \n",
       " 1348       1  (26.8, 27.0]  (30.8, 31.0]     2       2         1   \n",
       " \n",
       "      importance_same_race importance_same_religion  field pref_o_attractive  \\\n",
       " 0             (0.95, 1.0]              (0.95, 1.0]    121      (0.295, 0.3]   \n",
       " 1             (8.95, 9.0]              (4.95, 5.0]      7      (0.295, 0.3]   \n",
       " 2             (0.95, 1.0]              (0.95, 1.0]     69     (0.245, 0.25]   \n",
       " 3             (3.95, 4.0]              (4.95, 5.0]    192     (0.245, 0.25]   \n",
       " 4             (1.95, 2.0]              (2.95, 3.0]     23      (0.095, 0.1]   \n",
       " ...                   ...                      ...    ...               ...   \n",
       " 1344          (0.95, 1.0]              (0.95, 1.0]     70     (0.215, 0.22]   \n",
       " 1345          (0.95, 1.0]              (0.95, 1.0]    148     (0.155, 0.16]   \n",
       " 1346          (1.95, 2.0]              (1.95, 2.0]    121     (0.19, 0.195]   \n",
       " 1347          (4.95, 5.0]              (0.95, 1.0]     76      (0.2, 0.205]   \n",
       " 1348          (8.95, 9.0]              (6.95, 7.0]     23     (0.115, 0.12]   \n",
       " \n",
       "       ...       theater        movies     concerts         music  \\\n",
       " 0     ...   (1.95, 2.0]   (8.95, 9.0]  (6.95, 7.0]   (8.95, 9.0]   \n",
       " 1     ...   (8.95, 9.0]   (8.95, 9.0]  (8.95, 9.0]   (8.95, 9.0]   \n",
       " 2     ...   (4.95, 5.0]   (2.95, 3.0]  (2.95, 3.0]   (6.95, 7.0]   \n",
       " 3     ...   (4.95, 5.0]   (6.95, 7.0]  (5.95, 6.0]   (7.95, 8.0]   \n",
       " 4     ...   (1.95, 2.0]   (6.95, 7.0]  (7.95, 8.0]  (9.95, 10.0]   \n",
       " ...   ...           ...           ...          ...           ...   \n",
       " 1344  ...   (6.95, 7.0]   (6.95, 7.0]  (6.95, 7.0]  (9.95, 10.0]   \n",
       " 1345  ...  (9.95, 10.0]  (9.95, 10.0]  (5.95, 6.0]   (5.95, 6.0]   \n",
       " 1346  ...  (9.95, 10.0]  (9.95, 10.0]  (8.95, 9.0]   (8.95, 9.0]   \n",
       " 1347  ...   (7.95, 8.0]   (7.95, 8.0]  (6.95, 7.0]   (8.95, 9.0]   \n",
       " 1348  ...   (7.95, 8.0]   (5.95, 6.0]  (6.95, 7.0]   (6.95, 7.0]   \n",
       " \n",
       "           shopping         yoga interests_correlate  \\\n",
       " 0      (8.95, 9.0]  (1.95, 2.0]        (0.21, 0.22]   \n",
       " 1      (4.95, 5.0]  (6.95, 7.0]      (-0.24, -0.23]   \n",
       " 2      (1.95, 2.0]  (6.95, 7.0]        (0.18, 0.19]   \n",
       " 3      (8.95, 9.0]  (4.95, 5.0]        (0.07, 0.08]   \n",
       " 4      (4.95, 5.0]  (0.95, 1.0]        (0.35, 0.36]   \n",
       " ...            ...          ...                 ...   \n",
       " 1344   (4.95, 5.0]  (0.95, 1.0]      (-0.22, -0.21]   \n",
       " 1345  (9.95, 10.0]  (0.95, 1.0]        (0.43, 0.44]   \n",
       " 1346   (8.95, 9.0]  (4.95, 5.0]        (0.41, 0.42]   \n",
       " 1347  (9.95, 10.0]  (8.95, 9.0]        (0.45, 0.46]   \n",
       " 1348   (3.95, 4.0]  (1.95, 2.0]        (0.08, 0.09]   \n",
       " \n",
       "      expected_happy_with_sd_people          like decision  \n",
       " 0                      (4.95, 5.0]   (6.95, 7.0]        1  \n",
       " 1                      (5.95, 6.0]   (4.95, 5.0]        0  \n",
       " 2                      (4.95, 5.0]  (9.95, 10.0]        1  \n",
       " 3                      (6.95, 7.0]   (5.95, 6.0]        1  \n",
       " 4                      (5.95, 6.0]   (7.95, 8.0]        0  \n",
       " ...                            ...           ...      ...  \n",
       " 1344                   (4.95, 5.0]   (6.95, 7.0]        1  \n",
       " 1345                   (3.95, 4.0]   (4.95, 5.0]        0  \n",
       " 1346                   (3.95, 4.0]   (8.95, 9.0]        1  \n",
       " 1347                   (1.95, 2.0]   (3.95, 4.0]        0  \n",
       " 1348                   (4.95, 5.0]   (6.95, 7.0]        1  \n",
       " \n",
       " [1349 rows x 53 columns])"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "def train_test_split(df):\r\n",
    "    test_df = df.sample(random_state=47, frac=0.2)\r\n",
    "    train_df = df.drop(test_df.index)\r\n",
    "    return train_df, test_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "def binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner, number_of_bins):\r\n",
    "    for col in continuous_valued_columns:\r\n",
    "        min_val = 0\r\n",
    "        max_val = 10\r\n",
    "        if col=='age' or col == 'age_o':\r\n",
    "            min_val = 18\r\n",
    "            max_val = 58\r\n",
    "        elif col in preference_scores_of_participant or col in preference_scores_of_partner:\r\n",
    "            min_val = 0\r\n",
    "            max_val = 1\r\n",
    "        elif col == 'interests_correlate':\r\n",
    "            min_val = -1\r\n",
    "            max_val = 1\r\n",
    "        bins = np.linspace(min_val,max_val,num=number_of_bins+1)\r\n",
    "        df.loc[df[col] < min_val, col] = max_val\r\n",
    "        df.loc[df[col] > max_val, col] = max_val\r\n",
    "        df[col] = pd.cut(df[col],bins = bins, include_lowest=True)\r\n",
    "        # print(col, df[col].value_counts().sort_index().values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "\r\n",
    "bin_value_list = [2,5,10,50,100,200]\r\n",
    "for bin in bin_value_list:\r\n",
    "    print(\"Bin value\", bin)\r\n",
    "    df = pd.read_csv(\"./dating.csv\")\r\n",
    "    binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner, bin)\r\n",
    "    train_df, test_df = train_test_split(df)\r\n",
    "    train_df.to_csv('./trainingSet.csv', index = False)\r\n",
    "    test_df.to_csv('./testSet.csv', index = False)\r\n",
    "    # print(len(train_df), len(test_df))\r\n",
    "    resultant_table, train_df, test_df = nbc(1)\r\n",
    "    # print(\"Hello1\")\r\n",
    "    print(\"Training Accuracy: \",accuracy(resultant_table, train_df))\r\n",
    "    print(\"Testing Accuracy: \", accuracy(resultant_table, test_df))\r\n",
    "    # print(\"Hello2\")\r\n",
    "    # print(\"Testing Accuracy: \", round(accuracy(resultant_table, test_df), 2))\r\n",
    "    \r\n",
    "    # print(\"Hello3\")\r\n",
    "# print(len(train_df), len(test_df))\r\n",
    "\r\n",
    "# df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bin value 2\n",
      "Training Accuracy:  0.7512511584800742\n",
      "Testing Accuracy:  0.7175685693106004\n",
      "Bin value 5\n",
      "Training Accuracy:  0.7749768303985172\n",
      "Testing Accuracy:  0.7501853224610823\n",
      "Bin value 10\n",
      "Training Accuracy:  0.7883225208526413\n",
      "Testing Accuracy:  0.7516679021497406\n",
      "Bin value 50\n",
      "Training Accuracy:  0.7959221501390176\n",
      "Testing Accuracy:  0.7494440326167532\n",
      "Bin value 100\n",
      "Training Accuracy:  0.7949953660797034\n",
      "Testing Accuracy:  0.7524091919940696\n",
      "Bin value 200\n",
      "Training Accuracy:  0.8038924930491196\n",
      "Testing Accuracy:  0.7501853224610823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "preference_scores_of_participant = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']\r\n",
    "preference_scores_of_partner = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\r\n",
    "continuous_valued_columns = ['age', 'age_o', 'importance_same_race', 'importance_same_religion', \r\n",
    "        'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\r\n",
    "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\r\n",
    "       'attractive_important', 'sincere_important', 'intelligence_important',\r\n",
    "       'funny_important', 'ambition_important', 'shared_interests_important',\r\n",
    "       'attractive', 'sincere', 'intelligence', 'funny', 'ambition',\r\n",
    "       'attractive_partner', 'sincere_partner', 'intelligence_parter',\r\n",
    "       'funny_partner', 'ambition_partner', 'shared_interests_partner',\r\n",
    "       'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking',\r\n",
    "       'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\r\n",
    "       'music', 'shopping', 'yoga', 'interests_correlate',\r\n",
    "       'expected_happy_with_sd_people', 'like']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "def effect_of_bins(input_filename, bin_value_list):\r\n",
    "    # bin_value_list = [2,5,10,50,100,200]\r\n",
    "    for bin in bin_value_list:\r\n",
    "        print(\"Bin value\", bin)\r\n",
    "        df = pd.read_csv(input_filename)\r\n",
    "        binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner, bin)\r\n",
    "        train_df, test_df = train_test_split(df)\r\n",
    "        train_df.to_csv('./trainingSet.csv', index = False)\r\n",
    "        test_df.to_csv('./testSet.csv', index = False)\r\n",
    "        # print(len(train_df), len(test_df))\r\n",
    "        resultant_table, train_df, test_df = nbc(1)\r\n",
    "        # print(\"Hello1\")\r\n",
    "        print(\"Training Accuracy: \",round(accuracy(resultant_table, train_df), 2))\r\n",
    "        print(\"Testing Accuracy: \", accuracy(resultant_table, test_df))\r\n",
    "        # print(\"Hello2\")\r\n",
    "        # print(\"Testing Accuracy: \", round(accuracy(resultant_table, test_df), 2))\r\n",
    "\r\n",
    "bin_value_list = [2,5,10,50,100,200]\r\n",
    "input_filename = './dating.csv'\r\n",
    "effect_of_bins(input_filename, bin_value_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bin value 2\n",
      "Training Accuracy:  0.75\n",
      "Testing Accuracy:  0.7175685693106004\n",
      "Bin value 5\n",
      "Training Accuracy:  0.77\n",
      "Testing Accuracy:  0.7501853224610823\n",
      "Bin value 10\n",
      "Training Accuracy:  0.79\n",
      "Testing Accuracy:  0.7516679021497406\n",
      "Bin value 50\n",
      "Training Accuracy:  0.8\n",
      "Testing Accuracy:  0.7494440326167532\n",
      "Bin value 100\n",
      "Training Accuracy:  0.79\n",
      "Testing Accuracy:  0.7524091919940696\n",
      "Bin value 200\n",
      "Training Accuracy:  0.8\n",
      "Testing Accuracy:  0.7501853224610823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "fraction_list = [0.01,0.1,0.2,0.5,0.6,0.75,0.9,1]\r\n",
    "\r\n",
    "for frac in fraction_list:\r\n",
    "    # f = 0.2\r\n",
    "    print(\"Frac\", frac)\r\n",
    "    df = pd.read_csv(\"./dating.csv\")\r\n",
    "    binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner, 5)\r\n",
    "    train_df, test_df = train_test_split(df)\r\n",
    "    train_df.to_csv('./trainingSet.csv', index = False)\r\n",
    "    test_df.to_csv('./testSet.csv', index = False)\r\n",
    "    # print(len(train_df), len(test_df))\r\n",
    "    print(\"Now actual data samples for train and test\")\r\n",
    "    resultant_table, train_df, test_df = nbc(frac)\r\n",
    "    print(len(train_df), len(test_df))\r\n",
    "    # print(\"Hello1\")\r\n",
    "    print(\"Training Accuracy: \", accuracy(resultant_table, train_df))\r\n",
    "    print(\"Testing Accuracy: \", accuracy(resultant_table, test_df))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Frac 0.01\n",
      "Now actual data samples for train and test\n",
      "54 1349\n",
      "Training Accuracy:  0.9074074074074074\n",
      "Testing Accuracy:  0.6641957005189029\n",
      "Frac 0.1\n",
      "Now actual data samples for train and test\n",
      "540 1349\n",
      "Training Accuracy:  0.8425925925925926\n",
      "Testing Accuracy:  0.7390659747961453\n",
      "Frac 0.2\n",
      "Now actual data samples for train and test\n",
      "1079 1349\n",
      "Training Accuracy:  0.788693234476367\n",
      "Testing Accuracy:  0.7509266123054115\n",
      "Frac 0.5\n",
      "Now actual data samples for train and test\n",
      "2698 1349\n",
      "Training Accuracy:  0.7846553002223869\n",
      "Testing Accuracy:  0.7472201630837657\n",
      "Frac 0.6\n",
      "Now actual data samples for train and test\n",
      "3237 1349\n",
      "Training Accuracy:  0.7818968180413963\n",
      "Testing Accuracy:  0.7479614529280949\n",
      "Frac 0.75\n",
      "Now actual data samples for train and test\n",
      "4046 1349\n",
      "Training Accuracy:  0.7728620860108749\n",
      "Testing Accuracy:  0.7553743513713862\n",
      "Frac 0.9\n",
      "Now actual data samples for train and test\n",
      "4856 1349\n",
      "Training Accuracy:  0.7747116968698518\n",
      "Testing Accuracy:  0.7531504818383988\n",
      "Frac 1\n",
      "Now actual data samples for train and test\n",
      "5395 1349\n",
      "Training Accuracy:  0.7749768303985172\n",
      "Testing Accuracy:  0.7501853224610823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "bins = np.linspace(0,10,5+1)\r\n",
    "bins"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10.])"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
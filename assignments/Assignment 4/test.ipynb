{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 53)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_rows = 6500\n",
    "df = pd.read_csv('./dating-full.csv', nrows=num_of_rows)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns = ['race_Other'], axis=1, inplace=True)\n",
    "df.drop(columns = ['race_o', 'race', 'field'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df, label_encoding_list):\n",
    "    encoding_dict = {}\n",
    "    for col in label_encoding_list:\n",
    "        unique_val = np.unique(df[col].values)\n",
    "        val_dict = {}\n",
    "        encoding_value = 0\n",
    "        for val in unique_val:\n",
    "            val_dict[val]=encoding_value\n",
    "            df[col].replace(val, encoding_value, inplace=True)\n",
    "            encoding_value+=1\n",
    "        encoding_dict[col] = val_dict\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_list = ['gender']\n",
    "df = label_encoding(df, label_encoding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  age_o  samerace  importance_same_race  \\\n",
       "0       0   21     27         0                     2   \n",
       "1       0   21     22         0                     2   \n",
       "2       0   21     23         0                     2   \n",
       "3       0   21     24         0                     2   \n",
       "4       0   21     25         0                     2   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "0                         4               35.0            20.0   \n",
       "1                         4               60.0             0.0   \n",
       "2                         4               30.0             5.0   \n",
       "3                         4               30.0            10.0   \n",
       "4                         4               50.0             0.0   \n",
       "\n",
       "   pref_o_intelligence  pref_o_funny  ...  theater  movies  concerts  music  \\\n",
       "0                 20.0          20.0  ...        1      10        10      9   \n",
       "1                  0.0          40.0  ...        1      10        10      9   \n",
       "2                 15.0          40.0  ...        1      10        10      9   \n",
       "3                 20.0          10.0  ...        1      10        10      9   \n",
       "4                 30.0          10.0  ...        1      10        10      9   \n",
       "\n",
       "   shopping  yoga  interests_correlate  expected_happy_with_sd_people  like  \\\n",
       "0         8     1                 0.14                              3   7.0   \n",
       "1         8     1                 0.54                              3   7.0   \n",
       "2         8     1                 0.61                              3   7.0   \n",
       "3         8     1                 0.21                              3   6.0   \n",
       "4         8     1                 0.25                              3   6.0   \n",
       "\n",
       "   decision  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, preference_scores_of_participant, preference_scores_of_partner):\n",
    "    for ind in df.index:\n",
    "        total=0\n",
    "        for col in preference_scores_of_participant:\n",
    "            total+= df[col][ind]\n",
    "        for col in preference_scores_of_participant:\n",
    "            df.loc[ind, col] = df[col][ind]/total\n",
    "        total=0\n",
    "        for col in preference_scores_of_partner:\n",
    "            total+= df[col][ind]\n",
    "        for col in preference_scores_of_partner:\n",
    "            df.loc[ind, col] = df[col][ind]/total\n",
    "            # df[col][ind] = df[col][ind]/total\n",
    "    # for col in preference_scores_of_participant:\n",
    "    #     print(\"Mean of \"+ col + \": \" ,round(df[[col]].mean()[0], 2))\n",
    "    # for col in preference_scores_of_partner:\n",
    "    #     print(\"Mean of \"+ col + \": \" , round(df[[col]].mean()[0], 2))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_scores_of_participant = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "preference_scores_of_partner = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "df = normalize(df, preference_scores_of_participant, preference_scores_of_partner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner, number_of_bins):\n",
    "    binned_dict = {}\n",
    "    for col in continuous_valued_columns:\n",
    "        min_val = 0\n",
    "        max_val = 10\n",
    "        if col=='age' or col == 'age_o':\n",
    "            min_val = 18\n",
    "            max_val = 58\n",
    "        elif col in preference_scores_of_participant or col in preference_scores_of_partner:\n",
    "            min_val = 0\n",
    "            max_val = 1\n",
    "        elif col == 'interests_correlate':\n",
    "            min_val = -1\n",
    "            max_val = 1\n",
    "        bins = np.linspace(min_val,max_val,number_of_bins+1)\n",
    "        df.loc[df[col] < min_val, col] = max_val\n",
    "        df.loc[df[col] > max_val, col] = max_val\n",
    "        df[col] = pd.cut(df[col],bins, include_lowest=True, labels= np.arange(number_of_bins))\n",
    "        binned_dict[col] = df[col].value_counts().sort_index().values\n",
    "        # print(col, df[col].value_counts().sort_index().values)\n",
    "    return binned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender age age_o  samerace importance_same_race importance_same_religion  \\\n",
       "0       0   0     0         0                    0                        0   \n",
       "1       0   0     0         0                    0                        0   \n",
       "2       0   0     0         0                    0                        0   \n",
       "3       0   0     0         0                    0                        0   \n",
       "4       0   0     0         0                    0                        0   \n",
       "\n",
       "  pref_o_attractive pref_o_sincere pref_o_intelligence pref_o_funny  ...  \\\n",
       "0                 0              0                   0            0  ...   \n",
       "1                 1              0                   0            0  ...   \n",
       "2                 0              0                   0            0  ...   \n",
       "3                 0              0                   0            0  ...   \n",
       "4                 0              0                   0            0  ...   \n",
       "\n",
       "  theater movies concerts music shopping yoga interests_correlate  \\\n",
       "0       0      1        1     1        1    0                   1   \n",
       "1       0      1        1     1        1    0                   1   \n",
       "2       0      1        1     1        1    0                   1   \n",
       "3       0      1        1     1        1    0                   1   \n",
       "4       0      1        1     1        1    0                   1   \n",
       "\n",
       "  expected_happy_with_sd_people like decision  \n",
       "0                             0    1        1  \n",
       "1                             0    1        1  \n",
       "2                             0    1        1  \n",
       "3                             0    1        1  \n",
       "4                             0    1        0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_scores_of_participant = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "preference_scores_of_partner = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "continuous_valued_columns = ['age', 'age_o', 'importance_same_race', 'importance_same_religion', \n",
    "        'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
    "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\n",
    "       'attractive_important', 'sincere_important', 'intelligence_important',\n",
    "       'funny_important', 'ambition_important', 'shared_interests_important',\n",
    "       'attractive', 'sincere', 'intelligence', 'funny', 'ambition',\n",
    "       'attractive_partner', 'sincere_partner', 'intelligence_parter',\n",
    "       'funny_partner', 'ambition_partner', 'shared_interests_partner',\n",
    "       'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking',\n",
    "       'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
    "       'music', 'shopping', 'yoga', 'interests_correlate',\n",
    "       'expected_happy_with_sd_people', 'like']\n",
    "\n",
    "binned_dict = binning_continuous_valued_columns(df, continuous_valued_columns, preference_scores_of_participant, preference_scores_of_partner,2)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5793\n",
       "0     707\n",
       "Name: intelligence_parter, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intelligence_parter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    test_df = df.sample(random_state=47, frac=0.2)\n",
    "    train_df = df.drop(test_df.index)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = train_test_split(df)\n",
    "train_df.to_csv('trainingSet.csv', index = False)\n",
    "test_df.to_csv('testSet.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.values[0:, 0:49]\n",
    "Y_train = train_df.values[0:, 49:50]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_labels_data(df):\n",
    "    X = df.values[0:,0:49]\n",
    "    Y = df.values[0:,49:50]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = get_feature_labels_data(train_df)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajorityVote(data, target_label):\n",
    "    decision_column=data[target_label]\n",
    "    max_count=0\n",
    "    max_key=-100\n",
    "    decision_count = decision_column.value_counts()\n",
    "    for key in decision_count.keys():\n",
    "        value=decision_count[key]\n",
    "        if value>max_count:\n",
    "            max_count=value\n",
    "            max_key=key\n",
    "    return max_key\n",
    "\n",
    "def Build_Tree(tree_dict, data, feature_list, target_label, max_depth, min_example):\n",
    "    if len(feature_list)==1:#Only aim list left\n",
    "        return MajorityVote(data, target_label)\n",
    "    choose_feature=None\n",
    "    best_gain=-1000000\n",
    "\n",
    "    # decision_column=data[feature_list[-1]]\n",
    "    decision_column=data[target_label]\n",
    "    decision_count=decision_column.value_counts()\n",
    "    total_gini=1\n",
    "    for key in decision_count.keys():\n",
    "        value=decision_count[key]\n",
    "        total_gini-=(value/len(decision_column))**2\n",
    "\n",
    "    for feature in feature_list[:-1]:\n",
    "        study_column=data[feature]\n",
    "        feature_count=study_column.value_counts()\n",
    "        feature_gain=total_gini\n",
    "        for key in feature_count.keys():\n",
    "            value=feature_count[key]\n",
    "            percentage=value/len(study_column)\n",
    "            small_total_gini=1\n",
    "            study_data=data[data[feature]==key]\n",
    "            decision_column = study_data[feature_list[-1]]\n",
    "            decision_count = decision_column.value_counts()\n",
    "            for key in decision_count.keys():\n",
    "                value = decision_count[key]\n",
    "                small_total_gini -= (value / len(decision_column)) ** 2\n",
    "            feature_gain-=percentage*small_total_gini\n",
    "        if feature_gain>best_gain:\n",
    "            best_gain=feature_gain\n",
    "            choose_feature=feature\n",
    "\n",
    "    tmp_dict={}\n",
    "    study_column = data[choose_feature]\n",
    "    feature_count = study_column.value_counts()\n",
    "    use_feature=feature_list.copy()\n",
    "    use_feature.remove(choose_feature)\n",
    "\n",
    "    if  len(data)<= min_example or max_depth == 0:\n",
    "        tree_dict[choose_feature] = MajorityVote(data[data[choose_feature]], target_label)\n",
    "        return tree_dict\n",
    "\n",
    "    tmp_dict['major']=MajorityVote(data, feature_list)\n",
    "    for key in feature_count.keys():\n",
    "        value=feature_count[key]\n",
    "        if value <= min_example or max_depth == 1:\n",
    "            tmp_dict[key] = MajorityVote(data[data[choose_feature]==key], target_label)\n",
    "        else:\n",
    "            tmp_dict[key]=Build_Tree({},data[data[choose_feature]==key],use_feature, target_label, max_depth-1,min_example)\n",
    "            \n",
    "    tree_dict[choose_feature]=tmp_dict\n",
    "    return tree_dict\n",
    "\n",
    "def pred_label(tree_dict,data):\n",
    "    for key in tree_dict.keys():\n",
    "        new_dict=tree_dict[key]\n",
    "        value=data[key]\n",
    "        if type(new_dict)!=dict:\n",
    "            return new_dict\n",
    "        if value not in new_dict:\n",
    "            return new_dict['major']\n",
    "\n",
    "        now_dict=new_dict[value]\n",
    "        if type(now_dict)!=dict:\n",
    "            return now_dict\n",
    "        else:\n",
    "            return pred_label(now_dict,data)\n",
    "\n",
    "def pred(tree_dict,data):\n",
    "    num = len(data)\n",
    "    count=0\n",
    "    for i in range(len(data)):\n",
    "        pred=pred_label(tree_dict,data.iloc[i,:])\n",
    "        if pred==data.iloc[i,-1]:\n",
    "            count+=1\n",
    "    return float(count)/num\n",
    "\n",
    "def decisionTree(trainingSet, testSet):\n",
    "    max_depth=8\n",
    "    min_example=50\n",
    "    \n",
    "    #Now build tree using dict\n",
    "    tree_dict={}\n",
    "    feature_list=list(trainingSet.columns)\n",
    "    target_label = feature_list[-1]\n",
    "    #print(feature_list)\n",
    "\n",
    "    #It's only for 0 and 1 attribute. Therefore, we only need to find the feature\n",
    "    tree_dict=Build_Tree(tree_dict,trainingSet,feature_list, target_label, max_depth,min_example)\n",
    "    #print(tree_dict)\n",
    "    train_accu=pred(tree_dict,trainingSet)\n",
    "    test_accu=pred(tree_dict,testSet)\n",
    "    return train_accu,test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "test_df = pd.read_csv('testSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy DT: 0.77\n",
      "Testing Accuracy DT: 0.72\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = decisionTree(train_df, test_df)\n",
    "print('Training Accuracy DT: %.2f'%train_acc)\n",
    "print('Testing Accuracy DT: %.2f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list=list(train_df.columns)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(trainingSet):\n",
    "    max_depth=8\n",
    "    min_example=50\n",
    "    #Now build tree using dict\n",
    "    tree_dict={}\n",
    "    feature_list=list(trainingSet.columns)\n",
    "    target_label = feature_list[-1]\n",
    "    #print(feature_list)\n",
    "\n",
    "    #It's only for 0 and 1 attribute. Therefore, we only need to find the feature\n",
    "    tree_dict=Build_Tree(tree_dict,trainingSet,feature_list,target_label,max_depth,min_example)\n",
    "    return tree_dict\n",
    "\n",
    "def Evaluate_BT(Tree_lists, data):\n",
    "    count=0\n",
    "    for i in range(len(data)):\n",
    "        pred_list={}\n",
    "        for k in range(len(Tree_lists)):\n",
    "            pred=pred_label(Tree_lists[k],data.iloc[i,:])\n",
    "            if pred not in pred_list:\n",
    "                pred_list[pred]=1\n",
    "            else:\n",
    "                pred_list[pred] += 1\n",
    "        max_key=-1\n",
    "        max_count=-1000\n",
    "        for key in pred_list.keys():\n",
    "            if pred_list[key]>max_count:\n",
    "                max_count=pred_list[key]\n",
    "                max_key=key\n",
    "        if max_key==data.iloc[i,-1]:\n",
    "            count+=1\n",
    "    return count/len(data)\n",
    "\n",
    "def bagging(trainingSet,testSet):\n",
    "    Tree_lists = []\n",
    "    percent = 1\n",
    "    for k in range(30):\n",
    "        rand_state=random.randint(0,1000000)\n",
    "        tmp_train = trainingSet.sample(random_state=rand_state, replace=True,frac=percent)\n",
    "        tmp_tree = DT(tmp_train)\n",
    "        Tree_lists.append(tmp_tree)\n",
    "    train_accu=Evaluate_BT(Tree_lists,trainingSet)\n",
    "    test_accu = Evaluate_BT(Tree_lists, testSet)\n",
    "    return train_accu,test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BT: 0.79\n",
      "Testing Accuracy BT: 0.74\n"
     ]
    }
   ],
   "source": [
    "train_accu,test_accu=bagging(train_df,test_df)\n",
    "print('Training Accuracy BT: %.2f' % train_accu)\n",
    "print('Testing Accuracy BT: %.2f' % test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForests(trainingSet,testSet):\n",
    "    Tree_lists = []\n",
    "    percent = 0.5\n",
    "    for k in range(30):\n",
    "        rand_state = random.randint(0, 1000000)\n",
    "        tmp_train = trainingSet.sample(random_state=rand_state, replace=True,frac=percent)\n",
    "        tmp_feature=list(tmp_train.columns)\n",
    "        use_feature=random.sample(tmp_feature[:-1], int(np.sqrt(len(tmp_feature)-1)))+[tmp_feature[-1]]\n",
    "        tmp_train=tmp_train[use_feature]\n",
    "        #print(tmp_train.head(5))\n",
    "        tmp_tree = DT(tmp_train)\n",
    "        #print('finish %d trees'%(k+1))\n",
    "        Tree_lists.append(tmp_tree)\n",
    "    train_accu = Evaluate_BT(Tree_lists, trainingSet)\n",
    "    test_accu = Evaluate_BT(Tree_lists, testSet)\n",
    "    return train_accu, test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy RF: 0.69\n",
      "Testing Accuracy RF: 0.67\n"
     ]
    }
   ],
   "source": [
    "train_accu, test_accu = randomForests(train_df, test_df)\n",
    "print('Training Accuracy RF: %.2f' % train_accu)\n",
    "print('Testing Accuracy RF: %.2f' % test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "test_df = pd.read_csv('testSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(random_state=18, frac=1)\n",
    "percent = 0.5\n",
    "half_train_df = train_df.sample(random_state=32, frac=percent)\n",
    "len(half_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_split(train_set, fold_number):\n",
    "    # train_set = pd.read_csv(input_filename)\n",
    "    # train_set = train_set.sample(random_state=18, frac=1)\n",
    "    # fold_number = 10\n",
    "    fold_size=len(train_set)/fold_number\n",
    "    fold_data_list=[]\n",
    "    for i in range(fold_number):\n",
    "        new_fold=train_set.iloc[int(i*fold_size):int((i+1)*fold_size),:]\n",
    "        fold_data_list.append(new_fold)\n",
    "    return fold_data_list\n",
    "\n",
    "def get_train_test_data(fold_data_list, fraction, ind):\n",
    "    test_set = fold_data_list[ind]\n",
    "    rem_set = []\n",
    "    for k, data in enumerate(fold_data_list):\n",
    "        if(k!=ind):\n",
    "            rem_set.append(fold_data_list[k])\n",
    "    new_train_set = pd.concat(rem_set)\n",
    "    new_train_set = new_train_set.sample(random_state=32, frac=fraction)\n",
    "    # new_X_train, new_y_train = q2.get_features_labels(new_train_set)\n",
    "    # new_X_test, new_y_test = q2.get_features_labels(test_set)\n",
    "    return new_train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import trees as q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_models(fold_data_list, depth_list, fold_number):\n",
    "    dt_model_accuracy = []\n",
    "    bt_model_accuracy = []\n",
    "    rf_model_accuracy = []\n",
    "    for d in depth_list:\n",
    "        print(\"Current depth:\", d)\n",
    "        dt_frac_accuracy = []\n",
    "        bt_frac_accuracy = []\n",
    "        rf_frac_accuracy = []\n",
    "        for ind in range(fold_number):\n",
    "            print(\"Current fold:\", ind)\n",
    "            train_set, test_set = get_train_test_data(fold_data_list, 1, ind)\n",
    "            print(len(train_set), len(test_set))\n",
    "            # train dt\n",
    "            # train_acc,test_acc = q2.decisionTree(train_set, test_set, d) \n",
    "            dt_frac_accuracy.append(0)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # train bt\n",
    "            # train_acc,test_acc = q2.bagging(train_set, test_set, d) \n",
    "            train_acc,test_acc = q2.bagging(train_set, test_set, d)\n",
    "            bt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # #dataset for NBC\n",
    "            # train_df, test_df = get_train_test_data_nbc(fold_data_list_nbc, frac, ind)\n",
    "            # target_col = 'decision'\n",
    "            \n",
    "            #train rf\n",
    "            train_acc,test_acc = q2.randomForests(train_set, test_set, d) \n",
    "            rf_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "        dt_mean = np.mean(dt_frac_accuracy)\n",
    "        dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "        dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "        dt_model_accuracy.append([d, dt_mean, dt_std_err])\n",
    "\n",
    "        bt_mean = np.mean(bt_frac_accuracy)\n",
    "        bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "        bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "        bt_model_accuracy.append([d, bt_mean, bt_std_err])\n",
    "\n",
    "        rf_mean = np.mean(rf_frac_accuracy)\n",
    "        rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "        rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "        rf_model_accuracy.append([d, rf_mean, rf_std_err])\n",
    "\n",
    "    dt_data = np.array(dt_model_accuracy)\n",
    "    bt_data = np.array(bt_model_accuracy)\n",
    "    rf_data = np.array(rf_model_accuracy)\n",
    "    # dataset_size = [element*4680 for element in fraction_list]\n",
    "    plt.errorbar(depth_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "    plt.errorbar(depth_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "    plt.errorbar(depth_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "    plt.xlabel('Depth Limit')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.title('Performance of models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return dt_model_accuracy, bt_model_accuracy, rf_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 10\n",
    "fold_data_list = get_kfold_split(half_train_df, fold_number)\n",
    "depth_list = [3,5, 7, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 3\n",
      "Current fold: 0\n",
      "2340 260\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "decisionTree() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10060/244856469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_data_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10060/3992607370.py\u001b[0m in \u001b[0;36mcompare_models\u001b[1;34m(fold_data_list, depth_list, fold_number)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# train dt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mdt_frac_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# q2.print_accuracy(train_acc, test_acc, '1')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: decisionTree() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "compare_models(fold_data_list, depth_list, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trees as q2\n",
    "def compare_models(fold_data_list, fraction_list, fold_number):\n",
    "    dt_model_accuracy = []\n",
    "    bt_model_accuracy = []\n",
    "    rf_model_accuracy = []\n",
    "    for frac in fraction_list:\n",
    "        print(\"Current fraction:\", frac)\n",
    "        dt_frac_accuracy = []\n",
    "        bt_frac_accuracy = []\n",
    "        rf_frac_accuracy = []\n",
    "        for ind in range(fold_number):\n",
    "            print(\"Current fold:\", ind)\n",
    "            train_set, test_set = get_train_test_data(fold_data_list, frac, ind)\n",
    "            print(len(train_set), len(test_set))\n",
    "            # train dt\n",
    "            _ ,test_acc = q2.decisionTree(train_set, test_set, 8) \n",
    "            dt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # train bt\n",
    "            _ ,test_acc = q2.bagging(train_set, test_set, 8) \n",
    "            bt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # #dataset for NBC\n",
    "            # train_df, test_df = get_train_test_data_nbc(fold_data_list_nbc, frac, ind)\n",
    "            # target_col = 'decision'\n",
    "            \n",
    "            #train rf\n",
    "            _ ,test_acc = q2.randomForests(train_set, test_set, 8) \n",
    "            rf_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "        dt_mean = np.mean(dt_frac_accuracy)\n",
    "        dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "        dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "        dt_model_accuracy.append([frac, dt_mean, dt_std_err])\n",
    "\n",
    "        bt_mean = np.mean(bt_frac_accuracy)\n",
    "        bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "        bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "        bt_model_accuracy.append([frac, bt_mean, bt_std_err])\n",
    "\n",
    "        rf_mean = np.mean(rf_frac_accuracy)\n",
    "        rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "        rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "        rf_model_accuracy.append([frac, rf_mean, rf_std_err])\n",
    "\n",
    "    dt_data = np.array(dt_model_accuracy)\n",
    "    bt_data = np.array(bt_model_accuracy)\n",
    "    rf_data = np.array(rf_model_accuracy)\n",
    "    # dataset_size = [element*4680 for element in fraction_list]\n",
    "    plt.errorbar(fraction_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "    plt.errorbar(fraction_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "    plt.errorbar(fraction_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "    plt.xlabel('Fraction Size')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.title('Performance of models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return dt_model_accuracy, bt_model_accuracy, rf_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fraction: 0.05\n",
      "Current fold: 0\n",
      "234 520\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "decisionTree() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10060/2190742984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfold_data_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_kfold_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfraction_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcompare_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_data_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10060/1016911231.py\u001b[0m in \u001b[0;36mcompare_models\u001b[1;34m(fold_data_list, fraction_list, fold_number)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# train dt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mdt_frac_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m# q2.print_accuracy(train_acc, test_acc, '1')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: decisionTree() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "# test_df = pd.read_csv('testSet.csv')\n",
    "train_df = train_df.sample(random_state=18, frac=1)\n",
    "fold_number = 10\n",
    "fold_data_list = get_kfold_split(train_df, fold_number)\n",
    "fraction_list = [0.05, 0.75, 0.1, 0.15, 0.2]\n",
    "compare_models(fold_data_list, fraction_list, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import trees as q2\n",
    "from multiprocessing import Pool, pool\n",
    "from itertools import repeat\n",
    "import scipy.stats\n",
    "\n",
    "def get_kfold_split(train_set, fold_number):\n",
    "    fold_size=len(train_set)/fold_number\n",
    "    fold_data_list=[]\n",
    "    for i in range(fold_number):\n",
    "        new_fold=train_set.iloc[int(i*fold_size):int((i+1)*fold_size),:]\n",
    "        fold_data_list.append(new_fold)\n",
    "    return fold_data_list\n",
    "\n",
    "def get_train_test_data(fold_data_list, fraction, ind):\n",
    "    test_set = fold_data_list[ind]\n",
    "    rem_set = []\n",
    "    for k, data in enumerate(fold_data_list):\n",
    "        if(k!=ind):\n",
    "            rem_set.append(fold_data_list[k])\n",
    "    new_train_set = pd.concat(rem_set)\n",
    "    new_train_set = new_train_set.sample(random_state=32, frac=fraction)\n",
    "    return new_train_set, test_set\n",
    "\n",
    "\n",
    "\n",
    "def compare_models(pool, fold_data_list, depth_list, fold_number):\n",
    "    dt_model_accuracy = []\n",
    "    bt_model_accuracy = []\n",
    "    rf_model_accuracy = []\n",
    "    train_set_list = []\n",
    "    test_set_list = []\n",
    "    for ind in range(fold_number):\n",
    "        # print(\"Current fold:\", ind)\n",
    "        train_set_ind, test_set_ind = get_train_test_data(fold_data_list, 1, ind)\n",
    "        train_set_list.append(train_set_ind)\n",
    "        test_set_list.append(test_set_ind)\n",
    "    for d in depth_list:\n",
    "        print(\"Current depth:\", d)\n",
    "        dt_frac_accuracy = []\n",
    "        bt_frac_accuracy = []\n",
    "        rf_frac_accuracy = []\n",
    "        for ind in range(fold_number):\n",
    "            print(\"Current fold:\", ind)\n",
    "\n",
    "            _ ,test_acc = q2.decisionTree(train_set_list[ind], test_set_list[ind], d) \n",
    "            dt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # train bt\n",
    "            _ ,test_acc = q2.bagging(pool, train_set_list[ind], test_set_list[ind], d, 30) \n",
    "            bt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # #dataset for NBC\n",
    "            # train_df, test_df = get_train_test_data_nbc(fold_data_list_nbc, frac, ind)\n",
    "            # target_col = 'decision'\n",
    "            \n",
    "            #train rf\n",
    "            _ ,test_acc = q2.randomForests(pool, train_set_list[ind], test_set_list[ind], d, 30) \n",
    "            rf_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "        dt_mean = np.mean(dt_frac_accuracy)\n",
    "        dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "        dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "        dt_model_accuracy.append([d, dt_mean, dt_std_err])\n",
    "\n",
    "        bt_mean = np.mean(bt_frac_accuracy)\n",
    "        bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "        bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "        bt_model_accuracy.append([d, bt_mean, bt_std_err])\n",
    "\n",
    "        rf_mean = np.mean(rf_frac_accuracy)\n",
    "        rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "        rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "        rf_model_accuracy.append([d, rf_mean, rf_std_err])\n",
    "\n",
    "    dt_data = np.array(dt_model_accuracy)\n",
    "    bt_data = np.array(bt_model_accuracy)\n",
    "    rf_data = np.array(rf_model_accuracy)\n",
    "    # dataset_size = [element*4680 for element in fraction_list]\n",
    "    plt.errorbar(depth_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "    plt.errorbar(depth_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "    plt.errorbar(depth_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "    plt.xlabel('Depth Limit')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.title('Performance of models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return dt_model_accuracy, bt_model_accuracy, rf_model_accuracy\n",
    "\n",
    "def calculate_p_value(svm_data, lr_data):\n",
    "    p = scipy.stats.ttest_rel(lr_data, svm_data).pvalue\n",
    "    print(\"Value of p:\" , p)\n",
    "    if p<0.01:\n",
    "        return \"Accepting alternative hypothesis and rejecting null hypothesis\"\n",
    "    else:\n",
    "        return \"Accepting null hypothesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 3\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Current depth: 5\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Current depth: 7\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Current depth: 9\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received all the accuracies\n",
      "[[3, 0.7396153846153847, 0.008821873031674293], [5, 0.7323076923076923, 0.006969926947738023], [7, 0.7292307692307693, 0.009610768122544907], [9, 0.7230769230769231, 0.009278721601396015]]\n",
      "[[3, 0.7415384615384616, 0.008492948693757243], [5, 0.7430769230769231, 0.009179343932416185], [7, 0.7442307692307693, 0.00591482942278065], [9, 0.7469230769230769, 0.007859716784273729]]\n",
      "[[3, 0.731923076923077, 0.00788320812957524], [5, 0.7426923076923078, 0.007565297602252729], [7, 0.741153846153846, 0.0085146931829632], [9, 0.7411538461538462, 0.007051165500202255]]\n",
      "Value of p: 0.09657554057555477\n",
      "Accepting null hypothesis\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(processes=6)\n",
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "test_df = pd.read_csv('testSet.csv')\n",
    "train_df = train_df.sample(random_state=18, frac=1)\n",
    "percent = 0.5\n",
    "half_train_df = train_df.sample(random_state=32, frac=percent)\n",
    "len(half_train_df)\n",
    "fold_number = 10\n",
    "fold_data_list = get_kfold_split(half_train_df, fold_number)\n",
    "depth_list = [3,5, 7, 9]\n",
    "dt_model_accuracy_depth, bt_model_accuracy_depth, rf_model_accuracy_depth = compare_models(pool, fold_data_list, depth_list, fold_number)\n",
    "print(\"received all the accuracies\")\n",
    "pool.close()\n",
    "print(dt_model_accuracy_depth)\n",
    "print(bt_model_accuracy_depth)\n",
    "print(rf_model_accuracy_depth)\n",
    "\n",
    "# hypothesis testing\n",
    "    \n",
    "rf_model_accuracy_depth = [element[1] for element in rf_model_accuracy_depth]\n",
    "bt_model_accuracy_depth = [element[1] for element in bt_model_accuracy_depth]\n",
    "hypothesis = calculate_p_value(rf_model_accuracy_depth, bt_model_accuracy_depth)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trees as q2\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "import scipy.stats\n",
    "# import cv_depth as cvd\n",
    "\n",
    "def get_kfold_split(train_set, fold_number):\n",
    "    fold_size=len(train_set)/fold_number\n",
    "    fold_data_list=[]\n",
    "    for i in range(fold_number):\n",
    "        new_fold=train_set.iloc[int(i*fold_size):int((i+1)*fold_size),:]\n",
    "        fold_data_list.append(new_fold)\n",
    "    return fold_data_list\n",
    "\n",
    "def get_train_test_data(fold_data_list, fraction, ind):\n",
    "    test_set = fold_data_list[ind]\n",
    "    rem_set = []\n",
    "    for k, data in enumerate(fold_data_list):\n",
    "        if(k!=ind):\n",
    "            rem_set.append(fold_data_list[k])\n",
    "    new_train_set = pd.concat(rem_set)\n",
    "    new_train_set = new_train_set.sample(random_state=32, frac=fraction)\n",
    "    return new_train_set, test_set\n",
    "\n",
    "def compare_models(pool, fold_data_list, fraction_list, fold_number):\n",
    "    dt_model_accuracy = []\n",
    "    bt_model_accuracy = []\n",
    "    rf_model_accuracy = []\n",
    "    train_set_list = {}\n",
    "    test_set_list = {}\n",
    "    for ind in range(fold_number):\n",
    "        train_set_ind = {}\n",
    "        test_set_ind = {}\n",
    "        for frac in fraction_list:\n",
    "            train, test = get_train_test_data(fold_data_list, frac, ind)\n",
    "            train_set_ind[frac]=train\n",
    "            test_set_ind[frac]=test\n",
    "        train_set_list[ind] = train_set_ind\n",
    "        test_set_list[ind] = test_set_ind\n",
    "    for frac in fraction_list:\n",
    "        print(\"Current fraction:\", frac)\n",
    "        dt_frac_accuracy = []\n",
    "        bt_frac_accuracy = []\n",
    "        rf_frac_accuracy = []\n",
    "        for ind in range(fold_number):\n",
    "            print(\"Current fold:\", ind)\n",
    "            # train_set, test_set = get_train_test_data(fold_data_list, frac, ind)\n",
    "            # print(len(train_set), len(test_set))\n",
    "            # train dt\n",
    "            _ ,test_acc = q2.decisionTree(train_set_list[ind][frac], test_set_list[ind][frac], 8) \n",
    "            # print(\"DT acc:\", test_acc)\n",
    "            dt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # train bt\n",
    "            _ ,test_acc = q2.bagging(pool, train_set_list[ind][frac], test_set_list[ind][frac], 8, 30) \n",
    "            # print(\"Bagging acc\", test_acc)\n",
    "            bt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # #dataset for NBC\n",
    "            # train_df, test_df = get_train_test_data_nbc(fold_data_list_nbc, frac, ind)\n",
    "            # target_col = 'decision'\n",
    "            \n",
    "            #train rf\n",
    "            _ ,test_acc = q2.randomForests(pool, train_set_list[ind][frac], test_set_list[ind][frac], 8, 30) \n",
    "            # print(\"Random Forest acc\", test_acc)\n",
    "            rf_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "        dt_mean = np.mean(dt_frac_accuracy)\n",
    "        dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "        dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "        dt_model_accuracy.append([frac, dt_mean, dt_std_err])\n",
    "\n",
    "        bt_mean = np.mean(bt_frac_accuracy)\n",
    "        bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "        bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "        bt_model_accuracy.append([frac, bt_mean, bt_std_err])\n",
    "\n",
    "        rf_mean = np.mean(rf_frac_accuracy)\n",
    "        rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "        rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "        rf_model_accuracy.append([frac, rf_mean, rf_std_err])\n",
    "        print(\"DT:{}, Bagging:{}, Random Forest:{}\".format(dt_mean, bt_mean, rf_mean))\n",
    "\n",
    "    dt_data = np.array(dt_model_accuracy)\n",
    "    bt_data = np.array(bt_model_accuracy)\n",
    "    rf_data = np.array(rf_model_accuracy)\n",
    "    # dataset_size = [element*4680 for element in fraction_list]\n",
    "    plt.errorbar(fraction_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "    plt.errorbar(fraction_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "    plt.errorbar(fraction_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "    plt.xlabel('Fraction Size')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.title('Performance of models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return dt_model_accuracy, bt_model_accuracy, rf_model_accuracy\n",
    "\n",
    "def calculate_p_value(svm_data, lr_data):\n",
    "    p = scipy.stats.ttest_rel(lr_data, svm_data).pvalue\n",
    "    print(\"Value of p:\" , p)\n",
    "    if p<0.01:\n",
    "        return \"Accepting alternative hypothesis and rejecting null hypothesis\"\n",
    "    else:\n",
    "        return \"Accepting null hypothesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fraction: 0.05\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "DT:0.6942307692307692, Bagging:0.7088461538461539, Random Forest:0.7080769230769232\n",
      "Current fraction: 0.075\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "DT:0.6925000000000001, Bagging:0.7190384615384614, Random Forest:0.7215384615384616\n",
      "Current fraction: 0.1\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "DT:0.7144230769230769, Bagging:0.724423076923077, Random Forest:0.7221153846153846\n",
      "Current fraction: 0.15\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "DT:0.7111538461538461, Bagging:0.7263461538461539, Random Forest:0.7280769230769232\n",
      "Current fraction: 0.2\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "DT:0.7153846153846153, Bagging:0.7299999999999999, Random Forest:0.7317307692307693\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of p: 0.004164989924206315\n",
      "Accepting alternative hypothesis and rejecting null hypothesis\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(processes=6)\n",
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "# test_df = pd.read_csv('testSet.csv')\n",
    "train_df = train_df.sample(random_state=18, frac=1)\n",
    "fold_number = 10\n",
    "fold_data_list = get_kfold_split(train_df, fold_number)\n",
    "fraction_list = [0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "# fraction_list = [0.05, 0.075]\n",
    "dt_model_accuracy_frac, bt_model_accuracy_frac, rf_model_accuracy_frac = compare_models(pool, fold_data_list, fraction_list, fold_number)\n",
    "pool.close()\n",
    "\n",
    "# hypothesis testing\n",
    "    \n",
    "rf_model_accuracy = [element[1] for element in dt_model_accuracy_frac]\n",
    "bt_model_accuracy = [element[1] for element in bt_model_accuracy_frac]\n",
    "hypothesis = calculate_p_value(rf_model_accuracy, bt_model_accuracy)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trees analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import trees as q2\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "import scipy.stats\n",
    "\n",
    "def get_kfold_split(train_set, fold_number):\n",
    "    fold_size=len(train_set)/fold_number\n",
    "    fold_data_list=[]\n",
    "    for i in range(fold_number):\n",
    "        new_fold=train_set.iloc[int(i*fold_size):int((i+1)*fold_size),:]\n",
    "        fold_data_list.append(new_fold)\n",
    "    return fold_data_list\n",
    "\n",
    "def get_train_test_data(fold_data_list, fraction, ind):\n",
    "    test_set = fold_data_list[ind]\n",
    "    rem_set = []\n",
    "    for k, data in enumerate(fold_data_list):\n",
    "        if(k!=ind):\n",
    "            rem_set.append(fold_data_list[k])\n",
    "    new_train_set = pd.concat(rem_set)\n",
    "    new_train_set = new_train_set.sample(random_state=32, frac=fraction)\n",
    "    return new_train_set, test_set\n",
    "\n",
    "\n",
    "\n",
    "# def compare_models(fold_data_list, tree_list, fold_number):\n",
    "#     dt_model_accuracy = []\n",
    "#     bt_model_accuracy = []\n",
    "#     rf_model_accuracy = []\n",
    "#     for t in tree_list:\n",
    "#         print(\"No of trees:\", t)\n",
    "#         dt_frac_accuracy = []\n",
    "#         bt_frac_accuracy = []\n",
    "#         rf_frac_accuracy = []\n",
    "#         for ind in range(fold_number):\n",
    "#             print(\"Current fold:\", ind)\n",
    "#             train_set, test_set = get_train_test_data(fold_data_list, 1, ind)\n",
    "#             # print(len(train_set), len(test_set))\n",
    "#             # train dt\n",
    "#             _ ,test_acc = q2.decisionTree(train_set, test_set, 8) \n",
    "#             print(\"DT\", test_acc)\n",
    "#             dt_frac_accuracy.append(test_acc)\n",
    "#             # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "#             # train bt\n",
    "#             _ ,test_acc = q2.bagging(train_set, test_set, 8, t) \n",
    "#             bt_frac_accuracy.append(test_acc)\n",
    "#             print(\"BT\", test_acc)\n",
    "#             # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "#             # #dataset for NBC\n",
    "#             # train_df, test_df = get_train_test_data_nbc(fold_data_list_nbc, frac, ind)\n",
    "#             # target_col = 'decision'\n",
    "            \n",
    "#             #train rf\n",
    "#             _ ,test_acc = q2.randomForests(train_set, test_set, 8, t) \n",
    "#             rf_frac_accuracy.append(test_acc)\n",
    "#             print(\"RF\", test_acc)\n",
    "#             # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "#         dt_mean = np.mean(dt_frac_accuracy)\n",
    "#         dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "#         dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "#         dt_model_accuracy.append([t, dt_mean, dt_std_err])\n",
    "\n",
    "#         bt_mean = np.mean(bt_frac_accuracy)\n",
    "#         bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "#         bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "#         bt_model_accuracy.append([t, bt_mean, bt_std_err])\n",
    "\n",
    "#         rf_mean = np.mean(rf_frac_accuracy)\n",
    "#         rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "#         rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "#         rf_model_accuracy.append([t, rf_mean, rf_std_err])\n",
    "\n",
    "#         print(\"DT:{}, Bagging:{}, Random Forest:{}\".format(dt_mean, bt_mean, rf_mean))\n",
    "\n",
    "#     dt_data = np.array(dt_model_accuracy)\n",
    "#     bt_data = np.array(bt_model_accuracy)\n",
    "#     rf_data = np.array(rf_model_accuracy)\n",
    "#     # dataset_size = [element*4680 for element in fraction_list]\n",
    "#     plt.errorbar(tree_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "#     plt.errorbar(tree_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "#     plt.errorbar(tree_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "#     plt.xlabel('Number of Trees')\n",
    "#     plt.ylabel('Model Accuracy')\n",
    "#     plt.title('Performance of models')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     return dt_model_accuracy, bt_model_accuracy, rf_model_accuracy\n",
    "\n",
    "def compare_models(pool, fold_data_list, tree_list, fold_number):\n",
    "    # dt_model_accuracy = []\n",
    "    bt_model_accuracy = []\n",
    "    rf_model_accuracy = []\n",
    "    train_set_list = []\n",
    "    test_set_list = []\n",
    "    # pool1 = Pool(processes=5)\n",
    "    # pool2 = Pool(processes=5)\n",
    "    # pool3 = Pool(processes=5)\n",
    "    for ind in range(fold_number):\n",
    "        # print(\"Current fold:\", ind)\n",
    "        train_set_ind, test_set_ind = get_train_test_data(fold_data_list, 1, ind)\n",
    "        train_set_list.append(train_set_ind)\n",
    "        test_set_list.append(test_set_ind)\n",
    "    for t in tree_list:\n",
    "        print(\"No of trees:\", t)\n",
    "        # dt_frac_accuracy = []\n",
    "        bt_frac_accuracy = []\n",
    "        rf_frac_accuracy = []\n",
    "        for ind in range(fold_number):\n",
    "            print(\"Current fold:\", ind)\n",
    "            # print(\"with multiprocessing\")\n",
    "            # train_set, test_set = get_train_test_data(fold_data_list, 1, ind)\n",
    "            # print(len(train_set), len(test_set))\n",
    "            # train dt\n",
    "            # _ ,test_acc = q2.decisionTree(train_set_list[ind], test_set_list[ind], 8) \n",
    "            # # print(\"DT\", test_acc)\n",
    "            # dt_frac_accuracy.append(test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "            # train bt\n",
    "            _ ,test_acc = q2.bagging(pool, train_set_list[ind], test_set_list[ind], 8, t) \n",
    "            bt_frac_accuracy.append(test_acc)\n",
    "            \n",
    "            #train rf\n",
    "            _ ,test_acc = q2.randomForests(pool, train_set_list[ind], test_set_list[ind], 8, t) \n",
    "            rf_frac_accuracy.append(test_acc)\n",
    "            # print(\"RF\", test_acc)\n",
    "            # q2.print_accuracy(train_acc, test_acc, '1')\n",
    "\n",
    "        # dt_mean = np.mean(dt_frac_accuracy)\n",
    "        # dt_std = np.sqrt(np.var(dt_frac_accuracy))\n",
    "        # dt_std_err = dt_std/np.sqrt(fold_number)\n",
    "        # dt_model_accuracy.append([t, dt_mean, dt_std_err])\n",
    "\n",
    "        bt_mean = np.mean(bt_frac_accuracy)\n",
    "        bt_std = np.sqrt(np.var(bt_frac_accuracy))\n",
    "        bt_std_err = bt_std/np.sqrt(fold_number)\n",
    "        bt_model_accuracy.append([t, bt_mean, bt_std_err])\n",
    "\n",
    "        rf_mean = np.mean(rf_frac_accuracy)\n",
    "        rf_std = np.sqrt(np.var(rf_frac_accuracy))\n",
    "        rf_std_err = rf_std/np.sqrt(fold_number)\n",
    "        rf_model_accuracy.append([t, rf_mean, rf_std_err])\n",
    "\n",
    "        print(\"Bagging:{}, Random Forest:{}\".format( bt_mean, rf_mean))\n",
    "\n",
    "    # dt_data = np.array(dt_model_accuracy)\n",
    "    bt_data = np.array(bt_model_accuracy)\n",
    "    rf_data = np.array(rf_model_accuracy)\n",
    "    # dataset_size = [element*4680 for element in fraction_list]\n",
    "    plt.errorbar(tree_list, bt_data[:, 1], yerr=bt_data[:, 2], label='Bagging', marker = 'o')\n",
    "    # plt.errorbar(tree_list, dt_data[:, 1], yerr=dt_data[:, 2], label='Decision Tree', marker = 'o')\n",
    "    plt.errorbar(tree_list, rf_data[:, 1], yerr=rf_data[:, 2], label='Random Forest', marker = 'o')\n",
    "    plt.xlabel('Number of Trees')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.title('Performance of models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return bt_model_accuracy, rf_model_accuracy\n",
    "\n",
    "def calculate_p_value(svm_data, lr_data):\n",
    "    p = scipy.stats.ttest_rel(lr_data, svm_data).pvalue\n",
    "    print(\"Value of p:\" , p)\n",
    "    if p<0.01:\n",
    "        return \"Accepting alternative hypothesis and rejecting null hypothesis\"\n",
    "    else:\n",
    "        return \"Accepting null hypothesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n",
      "No of trees: 10\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Bagging:0.7469230769230769, Random Forest:0.7403846153846154\n",
      "No of trees: 20\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Bagging:0.7473076923076923, Random Forest:0.7407692307692308\n",
      "No of trees: 40\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Bagging:0.7426923076923078, Random Forest:0.7407692307692308\n",
      "No of trees: 50\n",
      "Current fold: 0\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 1\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 2\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 3\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 4\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 5\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 6\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 7\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 8\n",
      "In BT\n",
      "In RF\n",
      "Current fold: 9\n",
      "In BT\n",
      "In RF\n",
      "Bagging:0.7438461538461538, Random Forest:0.7426923076923078\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of p: 0.06890350891195932\n",
      "Accepting null hypothesis\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(processes=6)\n",
    "train_df = pd.read_csv('trainingSet.csv')\n",
    "# test_df = pd.read_csv('testSet.csv')\n",
    "train_df = train_df.sample(random_state=18, frac=1)\n",
    "percent = 0.5\n",
    "half_train_df = train_df.sample(random_state=32, frac=percent)\n",
    "print(len(half_train_df))\n",
    "fold_number = 10\n",
    "fold_data_list = get_kfold_split(half_train_df, fold_number)\n",
    "tree_list = [10, 20, 40, 50]\n",
    "# tree_list = [10, 20]\n",
    "bt_model_accuracy_trees, rf_model_accuracy_trees = compare_models(pool, fold_data_list, tree_list, fold_number)\n",
    "pool.close()\n",
    "\n",
    "# hypothesis testing\n",
    "    \n",
    "rf_model_accuracy = [element[1] for element in rf_model_accuracy_trees]\n",
    "bt_model_accuracy = [element[1] for element in bt_model_accuracy_trees]\n",
    "hypothesis = calculate_p_value(rf_model_accuracy, bt_model_accuracy)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
